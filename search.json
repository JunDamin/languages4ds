[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Practical Recipes for Data Science",
    "section": "",
    "text": "안녕하세요. 업무를 위한 데이터 과학 레시피를 작성하는 코다판다입니다.\n \n  \n   \n  \n    \n     GitHub\n  \n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nADP 준비 (2) : 탐색적 데이터 분석(EDA)\n\n\n\n\n\n\npython\n\n\nadp\n\n\ntest\n\n\ndata\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nADP 준비 (1)\n\n\n\n\n\n\nADP\n\n\ntest\n\n\ndata\n\n\ntutorial\n\n\n\n\n\n\n\n\n\nFeb 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n줄리아와 Turing.jl을 이용한 베이지안 통계 (1): 개관\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nPyechart Tutorial\n\n\n\n\n\n\npython\n\n\nvisualization\n\n\npyechart\n\n\n\n\n\n\n\n\n\nJul 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial of Algebra of Graphics\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAltair를 이용한 iris 데이터 시각화\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nLeo’s Syndrome with Julia Makie\n\n\n\n\n\n\njulia\n\n\nvisualization\n\n\nmakie\n\n\n\n\n\n\n\n\n\nDec 16, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nSIR모델을 사용해 코로나 발병 예측하기 with Julia\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nEconomist 시각화 가이드를 matplotlib에 적용하기\n\n\n\n\n\n\npython\n\n\nplot\n\n\nvisualization\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nJax를 사용해서 Regression을 그려 봅시다\n\n\n\n\n\n\npython\n\n\njax\n\n\nregression\n\n\ntutorial\n\n\n\n\n\n\n\n\n\nAug 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nJavis.jl를 사용해서 역행운동을 실행해 보자\n\n\n\n\n\n\nretrograde motion\n\n\nvisualization\n\n\njavis\n\n\njulia\n\n\n\n\n\n\n\n\n\nFeb 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n오프라인에서 패키지 설치하기\n\n\n\n\n\n\npython\n\n\nsetup\n\n\ntroubleshooting\n\n\nknowhow\n\n\n\n\n\n\n\n\n\nDec 23, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data_science/posts/retrospect_model.html",
    "href": "data_science/posts/retrospect_model.html",
    "title": "Javis.jl를 사용해서 역행운동을 실행해 보자",
    "section": "",
    "text": "유튜브를 보는 도중에 행성의 겉보기 역행 운동에 대한 영상을 보았습니다. 행성의 역행운동이란 지구에서 보기에 행성이 반대방향으로 움직이는 것처럼 보이는 현상입니다. 행성은 태양을 중심으로 돌고 있지만, 행성 간의 공전 속도의 차이로 뒤로 움직이는 듯이 보이는 현상을 말합니다. \n행성이 있고 보이는 각이 어떻게 바뀌는지를 시뮬레이션을 해보고자 하는데 줄리아에서 애니메이션을 만들 때 사용할 수 있는 Javis를 사용해서 그려보겠습니다.\n\nusing Javis\n\nfunction ground(args...) \n    background(\"white\") # canvas background\n    sethue(\"black\") # pen color\nend\nfunction object(p=O, color=\"black\")\nsethue(color)\ncircle(p, 25, :fill)\nreturn p\nend\n\n\nfunction path!(points, pos, color)\nsethue(color)\npush!(points, pos) # add pos to points\ncircle.(points, 2, :fill) # draws a circle for each point using broadcasting\nend\n\n\nfunction connector(p1, p2, color)\nsethue(color)\nline(p1,p2, :stroke)\nend\n\n\nfunction extender(points, p1, p2, r, color)\nsethue(color)\nd = p2 - p1\np3 = getpoint(p2, d, r, O)\nline(p1, p3, :stroke)\ncircle(p3, 2, :fill)\npush!(points, p3)\nif length(points) &gt; 200\npopat!(points, 1)\nend\ncircle.(points, 2, :fill)\nend\n\n\nimport Base.abs\n\n\nfunction abs(p::Point, p0::Point)\nd = p - p0\nr = sqrt(d.x^2 + d.y^2)\nreturn r\nend\n\n\nfunction getpoint(p, d, r, p0)\nλ = 0.001\nrate = 0.001\nnew_p = p\nwhile true\nnew_p = p + λ * d\nif r &lt; abs(new_p, p0)\nbreak\nend\nλ += rate\nend\nreturn new_p\nend\n\n\nn = 1000\nmyvideo = Video(2000, 2000)\nBackground(1:n, ground)\npath_of_red = Point[]\npath_of_blue = Point[]\nred_ball = Object(1:n, (args...)-&gt;object(O, \"#ff2211\"), Point(100,0))\nact!(red_ball, Action(anim_rotate_around(24π, O)))\nblue_ball = Object(1:n, (args...)-&gt;object(O, \"#1122ff\"), Point(200,0))\nact!(blue_ball, Action(anim_rotate_around(7π, O)))\nObject(1:n, (args...)-&gt;connector(pos(red_ball), pos(blue_ball), \"black\"))\nObject(1:n, (args...)-&gt;path!(path_of_red, pos(red_ball), \"red\"))\nObject(1:n, (args...)-&gt;path!(path_of_blue, pos(blue_ball), \"blue\"))\npoints = []\nObject(1:n, (args...)-&gt;extender(points, pos(red_ball), pos(blue_ball), 800, \"#112233\"))\n\n\nrender(\nmyvideo;\npathname=\"retrograde_motion.gif\"\n)\n\n\n\n\n역행운동"
  },
  {
    "objectID": "data_science/posts/pyechart_tutorial_01.html",
    "href": "data_science/posts/pyechart_tutorial_01.html",
    "title": "Pyechart Tutorial",
    "section": "",
    "text": "from pyecharts.charts import Bar\n\nbar = Bar()\nbar.add_xaxis([\"shirts\", \"cardigans\", \"chiffons\", \"trousers\", \"heels\", \"socks\"])\nbar.add_yaxis(\"Merchant A\", [5, 20, 36, 10, 75, 90])\nbar.render_notebook()\n\n\nfrom pyecharts import options as opts\nfrom pyecharts.charts import EffectScatter\nfrom pyecharts.faker import Faker\nfrom pyecharts.globals import SymbolType\n\nc = (\n    EffectScatter()\n    .add_xaxis(Faker.values(), )\n    .add_yaxis(\"\", Faker.values(), symbol=SymbolType.ARROW)\n    .set_global_opts(title_opts=opts.TitleOpts(title=\"EffectScatter\"), xaxis_opts=opts.AxisOpts(type_=\"value\"))\n    .render_notebook()\n)\nc\n\n\nimport pyecharts.options as opts\nfrom pyecharts.charts import MapGlobe\nfrom pyecharts.faker import POPULATION\n\ndata = [x for _, x in POPULATION[1:]]\nlow, high = min(data), max(data)\n\nc = (\n    MapGlobe()\n    .add_schema()\n    .add(\n        maptype=\"world\",\n        series_name=\"World Population\",\n        data_pair=POPULATION[1:],\n        is_map_symbol_show=True,\n        label_opts=opts.LabelOpts(is_show=True),\n    )\n    .set_global_opts(\n        visualmap_opts=opts.VisualMapOpts(\n            min_=low,\n            max_=high,\n            range_text=[\"max\", \"min\"],\n            is_calculable=True,\n            range_color=[\"lightskyblue\", \"yellow\", \"orangered\"],\n        )\n    )\n    .render_notebook()\n)\nc\n\n\nfrom pyecharts import options as opts\nfrom pyecharts.charts import Bar\nfrom pyecharts.faker import Faker\n\nc = (\n    Bar()\n    .add_xaxis(Faker.choose())\n    .add_yaxis(\"商家A\", Faker.values())\n    .add_yaxis(\"商家B\", Faker.values())\n    .set_global_opts(\n        title_opts=opts.TitleOpts(title=\"Bar-显示 ToolBox\"),\n        toolbox_opts=opts.ToolboxOpts(),\n        legend_opts=opts.LegendOpts(is_show=False),\n    )\n)\n\nc.render_notebook()\n\n\nimport datetime\nimport random\n\nfrom pyecharts import options as opts\nfrom pyecharts.charts import Calendar\n\n\nbegin = datetime.date(2017, 1, 1)\nend = datetime.date(2017, 12, 31)\ndata = [\n    [str(begin + datetime.timedelta(days=i)), random.randint(1000, 25000)]\n    for i in range((end - begin).days + 1)\n]\n\nc = (\n    Calendar()\n    .add(\"\", data, calendar_opts=opts.CalendarOpts(range_=\"2017\", ))\n    .set_global_opts(\n        title_opts=opts.TitleOpts(title=\"Calendar-2017年微信步数情况\"),\n        visualmap_opts=opts.VisualMapOpts(\n            max_=20000,\n            min_=500,\n            orient=\"horizontal\",\n            is_piecewise=True,\n            pos_top=\"230px\",\n            pos_left=\"100px\",\n        ),\n    )\n)\nc.render_notebook()\n\n\nfrom pyecharts import options as opts\nfrom pyecharts.charts import Line, Scatter\nfrom pyecharts.faker import Faker\n\nx = range(10)\nline = (\n    Line()\n    .add_xaxis(x)\n    .add_yaxis(\"商家A\", Faker.values())\n    .add_yaxis(\"商家B\", Faker.values())\n    .set_global_opts(title_opts=opts.TitleOpts(title=\"Overlap-line+scatter\"))\n)\nscatter = (\n    Scatter()\n    .add_xaxis(x)\n    .add_yaxis(\"商家A\", Faker.values())\n    .add_yaxis(\"商家B\", Faker.values())\n)\nline.overlap(scatter)\nline.render(\"../html/overlap_line_scatter.html\")\nline.render_notebook()"
  },
  {
    "objectID": "data_science/posts/iris_data_visualization_with_altair.html",
    "href": "data_science/posts/iris_data_visualization_with_altair.html",
    "title": "Altair를 이용한 iris 데이터 시각화",
    "section": "",
    "text": "altair는 grammar of graphics의 영향으로 DataFrame 혹은 json을 인풋으로 받고 그래프를 생성합니다. 그래프 생성은 각 성격을 지정하는 방식으로 이루어져 굉장히 유연하게 점진적 그래프를 그랠 수 있는 특징이 있습니다.\n이를 사용해서 다양한 그래프를 그려보려고 합니다.\n\n\n데이터 시각화에서 많이 쓰이는 iris 데이터 입니다. 유명한 Fisher경이 수집했다고 알려져 있습니다.\n꽃잎길이, 꽃입폭, 꽃바침길이, 꽃받침폭와 품종을 정리한 150개 기록이 있습니다.\n\n\nCode\nimport pandas as pd\nimport altair as alt\n\ndata = pd.read_csv(\n           \"https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/iris.csv\"\n       )\ndata"
  },
  {
    "objectID": "data_science/posts/iris_data_visualization_with_altair.html#altair란",
    "href": "data_science/posts/iris_data_visualization_with_altair.html#altair란",
    "title": "Altair를 이용한 iris 데이터 시각화",
    "section": "",
    "text": "altair는 grammar of graphics의 영향으로 DataFrame 혹은 json을 인풋으로 받고 그래프를 생성합니다. 그래프 생성은 각 성격을 지정하는 방식으로 이루어져 굉장히 유연하게 점진적 그래프를 그랠 수 있는 특징이 있습니다.\n이를 사용해서 다양한 그래프를 그려보려고 합니다.\n\n\n데이터 시각화에서 많이 쓰이는 iris 데이터 입니다. 유명한 Fisher경이 수집했다고 알려져 있습니다.\n꽃잎길이, 꽃입폭, 꽃바침길이, 꽃받침폭와 품종을 정리한 150개 기록이 있습니다.\n\n\nCode\nimport pandas as pd\nimport altair as alt\n\ndata = pd.read_csv(\n           \"https://raw.githubusercontent.com/blackdew/tensorflow1/master/csv/iris.csv\"\n       )\ndata"
  },
  {
    "objectID": "data_science/posts/iris_data_visualization_with_altair.html#다양한-그래프-그려보기",
    "href": "data_science/posts/iris_data_visualization_with_altair.html#다양한-그래프-그려보기",
    "title": "Altair를 이용한 iris 데이터 시각화",
    "section": "다양한 그래프 그려보기",
    "text": "다양한 그래프 그려보기\n\n산포도\niris 데이터로 가장 먼저 그려보는 것은 산포도 같습니다. iris데이터는 3개의 연속변수(continuous variables) 과 1개의 명목변수(nominal variable)로 구성되어 있습니다. 그래서 우선 연속변수 간 관계를 보기 위한 산포도를 그려 봅니다.\n\n\nCode\n(\n    alt.Chart(data)\n    .mark_point()\n    .encode(x=\"꽃잎길이\", y=\"꽃잎폭\")\n    .properties(width=400, height=400)\n)\n\n\n우선은 꽃잎길이와 꽃잎폭을 품종별로 산포도를 그려 봅니다.\n\n\nCode\n(alt.Chart(data)    # 그래프에 들어갈 데이터를 정의합니다.\n    .mark_point()    # 어떤 모양을 만들지 결정합니다.\n    .encode(x=\"꽃잎길이\", y=\"꽃잎폭\", color=\"품종\")    # 각각의 값이 어떤 의미를 가질지 정리합니다. \n    .properties(width=400, height=400)    # 크기를 지정합니다.\n)\n\n\n위에 그래프 처럼 altair는 기본적으로 여러 레이어로 구성되어 있습니다. mark, encode, properties가 있어 각각을 지정함으로 같은 데이터를 탐색할 때 보다 쉽게 접근할 수 있습니다.\n기본 설정을 사용할 때는 단순히 이름만 쓰면 됩니다만, 세부옵션을 지정하고 싶다면 해당되는 다양한 class를 사용할 수 있습니다.\n\n\nCode\n(alt.Chart(data, title=\"iris 데이터 시각화\")\n    .mark_point()\n    .encode(\n        x=alt.X(\"꽃잎길이\", ),\n        y=alt.Y(\"꽃잎폭\", ),\n        color=\"품종\")\n    .properties(width=400, height=400)\n)\n\n\naltair는 확장성을 위해서 그래프를 지정하고 다른 값들을 나중에 지정하면서 그래프를 그릴 수 있습니다.\n따라서 공통적으로 볼 내용을 미리 정하고 탐색적으로 그래프를 볼 수 있는 장점이 있습니다.\n색을 지정해서 차이를 쉽게 확인할 수 있습니다.\n\n\nCode\nbase = (alt.Chart(data, title=\"iris 데이터 시각화\")\n    .mark_point()\n    .properties(width=400, height=400)\n)\n\nbase.encode(\n        x=alt.X(\"꽃받침길이\", ),\n        y=alt.Y(\"꽃받침폭\", ),\n        color=\"품종\")\n\n\n모든 조합을 보고 싶으면 다음과 같이 facet을 쓰면 됩니다. 한글로하면 오류가 발생할 수 있어 아래와 같이 조금 조정했습니다.\n\n\nCode\nalt.Chart(data.rename({\"꽃잎길이\":\"sepal length\", \"꽃잎폭\": \"sepal width\", \"꽃받침길이\": \"petal length\", \"꽃받침폭\": \"petal width\"}, axis=1)).mark_point(\n    opacity=0.5,\n).encode(\n    x = alt.X(alt.repeat(\"column\"),  axis=alt.Axis(labelOverlap='parity'), type='quantitative'),\n    y = alt.Y(alt.repeat(\"row\"),  axis=alt.Axis(labelOverlap='parity'), type='quantitative'),\n    color =alt.Color('품종:N')\n).properties(width=100, height=100\n).repeat(\n    column=['sepal length', 'sepal width', \"petal length\", \"petal width\"],\n    row=['sepal length', 'sepal width', \"petal length\", \"petal width\"],\n)"
  },
  {
    "objectID": "data_science/posts/iris_data_visualization_with_altair.html#히스토그램",
    "href": "data_science/posts/iris_data_visualization_with_altair.html#히스토그램",
    "title": "Altair를 이용한 iris 데이터 시각화",
    "section": "히스토그램",
    "text": "히스토그램\n기본적으로 bin을 통해 히스토그램을 그릴 수 있습니다.\n\n\nCode\n(alt.Chart(data, title=\"iris 데이터 시각화\")\n    .mark_rect().encode(\n        alt.X('꽃받침길이:Q', bin=alt.Bin(maxbins=30), scale=alt.Scale(domain=[0, 8])),\n        alt.Y('count()'),\n        size='count()',\n        color=\"품종\")\n    .properties(width=400, height=400)\n)\n\n\n이것도 repeat을 통해서 반복해서 볼 수 있습니다. 정확한 이유는 모르지만 repeat을 한글컬럼명으로 하는 것은 되지 않습니다. 한글 인코딩 문제 등으로 추정하고 있습니다.\n\n\nCode\ndata_ = data.rename({\"꽃잎길이\":\"sepal length\", \"꽃잎폭\": \"sepal width\", \"꽃받침길이\": \"petal length\", \"꽃받침폭\": \"petal width\"}, axis=1)\n(alt.Chart(data_, )\n    .mark_rect().encode(\n        alt.X(alt.repeat(\"row\"), bin=alt.Bin(maxbins=30), scale=alt.Scale(domain=[0, 8])),\n        alt.Y('count()'),\n        size='count()',\n        color=\"품종\")\n    .properties(width=400, height=400)\n).repeat(\n    row=['sepal length', 'sepal width', \"petal length\", \"petal width\"],\n)\n\n\n\ntick 그래프\n히스토그램과 유사하나 경향을 압축해서 볼 수 있는 그래프로 tick 그래프가 있습니다.\n1차원의 값을 비교하기 위해서 아래와 같이 그래프를 그릴 수 있습니다.\n\n\nCode\n(alt.Chart(data, title=\"iris 데이터 시각화\")\n    .mark_tick()\n    .encode(\n        x=alt.X(\"꽃받침길이\", scale=alt.Scale(domain=[0, 8])),\n        y=alt.Y(\"품종\",),\n        color=\"품종\")\n    .properties(width=400, height=150)\n)\n\n\n\n\n2차원 히스토그램\n아래 그래프는 각 구간별 갯수를 크기로 하는 시각화입니다.\n\n\nCode\n(\n    alt.Chart(data, title=\"iris 데이터 시각화\")\n    .mark_circle(opacity=0.5).encode(\n        alt.X('꽃받침길이:Q', bin=True, scale=alt.Scale(domain=[0, 8])),\n        alt.Y('꽃받침폭:Q', bin=True, scale=alt.Scale(domain=[0, 3])),\n        size='count()',\n        color=alt.Color(\"품종\"))\n    .properties(width=400, height=400)\n)\n\n\n사각형으로도 할 수 있습니다.\n\n\nCode\nrect = alt.Chart(data, title=\"Iris 데이터 시각화\").mark_square(opacity=0.5).encode(\n    x=alt.X('꽃받침길이:Q', bin=True),\n    y=alt.Y('꽃잎길이:Q', bin=True),\n    size=\"count()\",\n    color=alt.Color('품종')\n).properties(width=400, height=400)\nrect\n\n\n\n\nheatmap\n이러한 방식을 조금 비틀어서 히트맵 형식으로도 표현이 가능합니다.\n\n\nCode\nrect = alt.Chart(data, title=\"Iris 데이터 시각화\").mark_rect().encode(\n    alt.X('꽃받침길이:Q', bin=True),\n    alt.Y('꽃잎길이:Q', bin=True),\n    alt.Color('count()',\n        scale=alt.Scale(scheme='greenblue'),\n        legend=alt.Legend(title='개체수')\n    )\n).properties(width=400, height=400)\nrect\n\n\n\n\npoint with error bar\n\n\nCode\n    error_bars = alt.Chart(data).mark_errorbar(extent='stdev').encode(\n      x=alt.X('꽃받침길이:Q', scale=alt.Scale(zero=False)),\n      y=alt.Y('품종:N')\n    )\n\n    points = alt.Chart(data).mark_point(filled=True, color='black').encode(\n      x=alt.X('꽃받침길이:Q', aggregate='mean'),\n      y=alt.Y('품종:N'),\n    )\n\n    chart = error_bars + points\n    chart\n\n\n아래와 같이 하면 각 품종별로 길이를 볼 수 있습니다.\n\n\nCode\nerror_bars = alt.Chart(data).transform_fold(['꽃받침길이', '꽃받침폭', '꽃잎길이', \"꽃잎폭\"],\nas_=['측정', '길이']).mark_errorbar(extent='stdev').encode(\nx=alt.X(\"길이:Q\", scale=alt.Scale(zero=False)),\ny=alt.Y('측정:N')\n)\n\npoints = alt.Chart(data).transform_fold(['꽃받침길이', '꽃받침폭', '꽃잎길이', \"꽃잎폭\"],\nas_=['측정', '길이']).mark_point(filled=True, color='black').encode(\nx=alt.X(\"길이:Q\", aggregate='mean'),\ny=alt.Y('측정:N'),\n)\nchart = error_bars + points\nchart.facet(row=\"품종:N\")\n\n\nfacet을 쓰지 않으면 전체 분포를 볼 수 있습니다.\n\n\nCode\nchart\n\n\n\n\nviolin plot\nseaborn이나 matplotlib과는 다르게 먼저 데이터를 density를 나타내도록 변경한 다음 그래프를 지정합니다.\n\n\nCode\nalt.Chart(data).transform_density(\n    '꽃잎길이',\n    as_=['꽃잎길이', 'density'],\n    extent=[3, 9],\n    groupby=['품종']\n).mark_area(orient='horizontal').encode(\n    y='꽃잎길이:Q',\n    color='품종:N',\n    x=alt.X(\n        'density:Q',\n        stack='center',\n        impute=None,\n        title=None,\n        axis=alt.Axis(labels=False, values=[0],grid=False, ticks=True),\n    ),\n    column=alt.Column(\n        '품종:N',\n        header=alt.Header(\n            titleOrient='bottom',\n            labelOrient='bottom',\n            labelPadding=0,\n        ),\n    )\n).properties(\n    width=100\n).configure_facet(\n    spacing=0\n).configure_view(\n    stroke=None\n)"
  },
  {
    "objectID": "data_science/posts/iris_data_visualization_with_altair.html#stripplot",
    "href": "data_science/posts/iris_data_visualization_with_altair.html#stripplot",
    "title": "Altair를 이용한 iris 데이터 시각화",
    "section": "stripplot",
    "text": "stripplot\n한 값을 랜덤하게 부여하여 점이 모여 있는 값을 보여주는 자료 입니다. 히스토그램이나 tick plot과 유사한 목적을 가지고 있습니다.\n\n\nCode\nbrush = alt.selection(type='interval')\nbase = alt.Chart(data).add_selection(brush)\n\nstripplot =  base.mark_circle(size=8).encode(\n    x=alt.X(\n        'jitter:Q',\n        title=None,\n        axis=alt.Axis(values=[0], ticks=True, grid=False, labels=False),\n    ),\n    y=alt.Y('꽃잎길이:Q', scale=alt.Scale(domain=[3, 9])),\n    color=alt.condition(brush, '품종:N', alt.value('grey')),\n    column=alt.Column(\n        '품종:N',\n        header=alt.Header(\n            labelAngle=-90,\n            titleOrient='top',\n            labelOrient='bottom',\n            labelAlign='right',\n            labelPadding=0\n        ),\n    ),\n).transform_calculate(\n    # Generate Gaussian jitter with a Box-Muller transform\n    jitter='sqrt(-2*log(random()))*cos(2*PI*random())'\n).properties(width=50)\nstripplot\n\n\n\ntick plot\n값의 분포를 보기 위해서 사용하는 차트 입니다. 특히 여러 카테고리별로 값의 분포가 차이가 나는지 보고 싶을 때 유용합니다.\n\n\nCode\ntick_xaxis = alt.Axis(domain=False, ticks=False, orient=\"top\", labelAlign=\"right\")\ntick_yaxis = alt.Axis(domain=False, labels=False, ticks=False)\ntick_plot = base.mark_tick().encode(\n                x=alt.X(\"품종\", axis=tick_xaxis, title=\"\"),\n                y=alt.Y(\"꽃잎길이\", scale=alt.Scale(domain=[3, 9]), axis=tick_yaxis, title=\"\"),\n                color=alt.condition(brush, '품종', alt.value('grey'),),\n)\ntick_plot\n\n\n두 그래프를 병렬로 배치하면 좀더 느낌의 차이를 보기 좋습니다. 유사한 듯 인상이 다른 것을 볼 수 있습니다.\n\n\nCode\nhconcat = alt.hconcat(stripplot, tick_plot)\n\nhconcat.configure_facet(\n    spacing=0\n).configure_view(\n   stroke=None\n).display()\n\n\n\n\nQQ plot\n누적비율과 값의 모습을 같이 보여주는 QQ plot을 그려 봅니다.\n\n\nCode\nbase = alt.Chart(data).transform_quantile(\n        '꽃잎길이',\n        step=0.01,\n        as_ = ['p', '꽃잎길이']\n    ).transform_calculate(\n        uniform = 'quantileUniform(datum.p)'\n    )\n\n\nqq = base.mark_point().encode(\n    x=alt.X('uniform:Q', title=\"quantile\"), \n    y=alt.Y('꽃잎길이:Q', scale=alt.Scale(domain=[4, 8]), title=\"꽃잎길이\")\n    ).properties(title=\"QQ plot\")\n\nline = base.mark_rule(color=\"red\", strokeDash=(8,8), strokeWidth=3).encode(\n    x=\"min(uniform):Q\",\n    x2=\"max(uniform):Q\",\n    y=\"min(꽃잎길이):Q\",\n    y2=\"max(꽃잎길이):Q\",\n)\n\nqq + line"
  },
  {
    "objectID": "data_science/posts/iris_data_visualization_with_altair.html#멀티-차트",
    "href": "data_science/posts/iris_data_visualization_with_altair.html#멀티-차트",
    "title": "Altair를 이용한 iris 데이터 시각화",
    "section": "멀티 차트",
    "text": "멀티 차트\n\n그래프 합치기\n특징은 다양한 그래프를 그릴 수 있습니다.\n이번에 그릴 그래프를 위한 기본 설정입니다. x, y 범주와 투명도, 데이터를 정의하고 있습니다.\n\n\nCode\nbase = alt.Chart(data)\n\nxscale = alt.Scale(domain=(4.0, 8.0))\nyscale = alt.Scale(domain=(1.9, 4.55))\n\nbar_args = {'opacity': .3, 'binSpacing': 0}\n\n\n메인이 될 산포도입니다.\n\n\nCode\npoints = base.mark_circle().encode(\n    alt.X('꽃잎길이', scale=xscale),\n    alt.Y('꽃잎폭', scale=yscale),\n    color='품종',\n)\npoints\n\n\n위쪽에 사용할 보조 히스토그램입니다.\n\n\nCode\ntop_hist = base.mark_bar(**bar_args).encode(\n    alt.X('꽃잎길이:Q',\n          # when using bins, the axis scale is set through\n          # the bin extent, so we do not specify the scale here\n          # (which would be ignored anyway)\n          bin=alt.Bin(maxbins=20, extent=xscale.domain),\n          stack=None,\n          title=''\n          ),\n    alt.Y('count()', stack=None, title=''),\n    alt.Color('품종:N'),\n).properties(height=60)\ntop_hist\n\n\n오른쪽에 사용할 히스토그램입니다.\n\n\nCode\nright_hist = base.mark_bar(**bar_args).encode(\n    alt.Y('꽃잎폭:Q',\n          bin=alt.Bin(maxbins=20, extent=yscale.domain),\n          stack=None,\n          title='',\n          ),\n    alt.X('count()', stack=None, title=''),\n    alt.Color('품종:N'),\n).properties(width=60)\nright_hist\n\n\n3개의 그래프를 아래와 같이 쉽게 합칠 수 있습니다.\n\n\nCode\nchart = top_hist & (points | right_hist)\nchart\n\n\n위를 방식은 아래와 같이 tick plot으로 바꾸어 사용할 수 있습니다.\n\n\nCode\n# Configure the options common to all layers\nbrush = alt.selection(type='interval')\nbase = alt.Chart(data).add_selection(brush)\n\n# Configure the points\npoints = base.mark_point().encode(\n    x=alt.X('꽃잎길이', title=''),\n    y=alt.Y('꽃받침길이', title=''),\n    color=alt.condition(brush, '품종', alt.value('grey')),\n).properties(title=\"Iris 데이터 시각화\")\n\n# Configure the ticks\ntick_axis = alt.Axis(labels=False, domain=False, ticks=False)\n\nx_ticks = base.mark_tick().encode(\n    alt.X('꽃잎길이', axis=tick_axis),\n    alt.Y('품종', title='', axis=tick_axis),\n    color=alt.condition(brush, '품종', alt.value('lightgrey'))\n)\n\ny_ticks = base.mark_tick().encode(\n    alt.X('품종', title='', axis=tick_axis),\n    alt.Y('꽃받침길이', axis=tick_axis),\n    color=alt.condition(brush, '품종', alt.value('lightgrey'))\n)\n\n# Build the chart\n(y_ticks | (points & x_ticks))\n\n\n\n\nfacet plot\nfacet chart를 이용하여 여러 측면을 한번에 관찰 할 수 있습니다. 우선 tidy하게 데이터를 바꾸고 facet을 적용하는 방법입니다.\n\n\nCode\nalt.Chart(data).transform_fold(\n    ['꽃받침길이', '꽃받침폭', '꽃잎길이', \"꽃잎폭\"],\n    as_=['측정', '길이']\n).mark_bar(\n    opacity=0.5,\n    binSpacing=0\n).encode(\n    alt.X('길이:Q', bin=alt.Bin(maxbins=100)),\n    alt.Y('count()', stack=None),\n    alt.Color('품종:N'),\n    row=alt.Row(\"측정:N\", title=\"측정 항목\"),\n)\n\n\nrepeat을 사용해서 유사한 작업을 할 수 있습니다.\n\n\nCode\nalt.Chart(data.rename({\"꽃잎길이\":\"sepal length\", \"꽃잎폭\": \"sepal width\", \"꽃받침길이\": \"petal length\", \"꽃받침폭\": \"petal width\"}, axis=1)).mark_bar(\n    opacity=0.5,\n    binSpacing=0\n).encode(\n    x = alt.X(alt.repeat(\"row\"), bin=alt.Bin(maxbins=30)),\n    y = alt.Y(\"count()\", stack=None),\n    color =alt.Color('품종:N')\n).repeat(\n    row=['sepal length', 'sepal width', \"petal length\", \"petal width\"],\n)\n\n\nFacet을 조금 이용하면 아래와 같이 밀도 함수를 표현할 수 있습니다.\n\n\nCode\nplot = alt.Chart(data).transform_fold(\n    ['꽃잎길이',\n     '꽃잎폭',\n     '꽃받침길이',\n     '꽃받침폭'],\n    as_ = ['Measurement_type', 'value']\n).transform_density(\n    density='value',\n    bandwidth=0.3,\n    groupby=['Measurement_type', \"품종\"],\n    extent= [0, 8]\n).mark_area().encode(\n    alt.X('value:Q'),\n    alt.Y('density:Q'),\n    alt.Row('Measurement_type:N'),\n    color=alt.Color(\"품종:N\")\n).properties(width=300, height=50)\nplot"
  },
  {
    "objectID": "data_science/posts/installing_packages_under_offline.html",
    "href": "data_science/posts/installing_packages_under_offline.html",
    "title": "오프라인에서 패키지 설치하기",
    "section": "",
    "text": "인터넷이 연될되지 않은 상황에서 파이썬 패키지를 설치하고자 할 때 알아두어야 할 것을 정리해 보고자 한다."
  },
  {
    "objectID": "data_science/posts/installing_packages_under_offline.html#패키지를-받기",
    "href": "data_science/posts/installing_packages_under_offline.html#패키지를-받기",
    "title": "오프라인에서 패키지 설치하기",
    "section": "패키지를 받기",
    "text": "패키지를 받기\npypi에서 whl 하나를 받을 순 있긴 한데 관련된 패키지가 없으면 결국 작동이 안된다. pip download {{패키지 이름}} 형식으로 작성하면 된다.\n단 운영하고자 하는 OS에서 가동이 가능한 파일을 받아야 한다."
  },
  {
    "objectID": "data_science/posts/installing_packages_under_offline.html#패키지-파일을-옮기기",
    "href": "data_science/posts/installing_packages_under_offline.html#패키지-파일을-옮기기",
    "title": "오프라인에서 패키지 설치하기",
    "section": "패키지 파일을 옮기기",
    "text": "패키지 파일을 옮기기\n패키지 파일을 설치하고자 하는 컴퓨터로 옮겨야 한다. 이 부분은 망분리 방식에 따라 다르기 때문에 별도로 다루진 않는다."
  },
  {
    "objectID": "data_science/posts/installing_packages_under_offline.html#설치하기",
    "href": "data_science/posts/installing_packages_under_offline.html#설치하기",
    "title": "오프라인에서 패키지 설치하기",
    "section": "설치하기",
    "text": "설치하기\npip에서 링크 옵션을 지정해서 할 수 있다.\n–no-index옵션과 –find-links옵션을 쓰면 설치할 수 있다.\n패키지 중에서 API wrapper형식으로 된 경우 해당 소프트웨어를 설치해야 한다. altair를 쓰고자 하면 vega를 설치해야 한다.\n예시\npip install --no-index --find-links {패키지가 있는 경로} {설치할 패키지}"
  },
  {
    "objectID": "data_science/posts/economist_style_with_matplotlib.html",
    "href": "data_science/posts/economist_style_with_matplotlib.html",
    "title": "Economist 시각화 가이드를 matplotlib에 적용하기",
    "section": "",
    "text": "Economist는 영국에서 발간하는 경제 주간지로 전세계에 일어나고 있는 뉴스를 전달합니다. 뉴스를 전달하는 과정에서 여러가지 차트를 제시하곤 하는데, 설득력 있게 전달하는 방식을 matplotlib에서 적용을 해보고자 합니다.\n예시로 사용할 데이터는 한스 로슬링 박사님이 사용하셨던 gap minder 데이터를 사용해보고자 합니다.\n우선 필요한 패키지를 불러옵니다.\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ngapminder = pd.read_csv(\"https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder.csv\")\n\n\n기본 그래프 출력하기\nmatplotlib에서 기본적으로 출력할 수 있는 방식은 다음과 같습니다. seaborn을 쓰면 조금 다르겠지만, 크게 다르지 않습니다.\n\ncountries = ['United Kingdom', 'United States', 'France', 'China', 'Japan', 'Korea Rep.', 'Ghana', 'Somalia', 'South Africa',]\n\ndata = gapminder.loc[gapminder.country.isin(countries)]\nfig, ax = plt.subplots(1, 1)\n\nfor country, df in gapminder.groupby(\"country\"):\n    ax.plot(df[\"year\"], df[\"lifeExp\"], label=country)\n\nplt.show()\n\n보시면 알겠지만, 너무 많은 선이 노출되어 있어서 무엇을 전달하려고 하는지 전달이 되지 않습니다. 전반적으로 기대 수명이 개선 되고 있는 것을 확인할 수 있습니다만, 너무 복잡해서 무엇을 전달하고자 하는지 이해가 되지 않습니다.\n\n\n스타일 적용하기\nEconomist에서 방식은 메시지를 집중하는 방식을 사용합니다.\n앞으로 진행해보고자 하는 것을 정리하자면\n\n비교하고자 하는 자료를 강조하고 그 외의 자료는 간략하게\n세로축과 보조선을 제외하기\n가로선을 설정하기\n태그 넣기\n\n정도 입니다. 아래에 그 방식을 따라하면 됩니다.\n\n# 플롯 설정하기\nfig, ax = plt.subplots(figsize=(8,6))\n\n# 1. 보조선 그리기\n# zorder를 통해서 보여지는 순서를 지정할 수 있습니다.\n\nax.yaxis.set_ticks(range(25, 100, 15))\nax.grid(which=\"major\", axis='y', color='#758D99', alpha=0.6, zorder=1, )\n\n# 불필요한 테두리 제거하기\nax.spines[['top','right','left']].set_visible(False)\n\n# 축 눈금 스타일 조정하기\nax.set_yticklabels(ax.get_yticklabels(),            # Set labels again\n                   ha = 'right',                 # Set horizontal alignment to right\n                   verticalalignment='bottom')   # Set vertical alignment to make labels on top of gridline      \n\n\nax.yaxis.set_tick_params(pad=11,             # Pad tick labels so they don't go over y-axis\n                         labeltop=True,      # Put x-axis labels on top\n                         labelbottom=False,  # Set no x-axis labels on bottom\n                         bottom=False,       # Set no ticks on bottom\n                         labelsize=11)       # Set tick label size\n\nax.xaxis.set_tick_params(labelsize=11)        # Set tick label size\n\n\n# Economist 스타일 넣기\nax.plot([0.12, .9],                  # Set width of line\n        [.98, .98],                  # Set height of line\n        transform=fig.transFigure,   # Set location relative to plot\n        clip_on=False, \n        color='#E3120B', \n        linewidth=.6)\nax.add_patch(plt.Rectangle((0.12,.98),                 # Set location of rectangle by lower left corder\n                           0.04,                       # Width of rectangle\n                           -0.02,                      # Height of rectangle. Negative so it goes down.\n                           facecolor='#E3120B', \n                           transform=fig.transFigure, \n                           clip_on=False, \n                           linewidth = 0))\n\n\n# Plot data\n# Loop through country names and plot each one.\nfor name, df in gapminder.groupby(\"country\"):\n    ax.plot(df['year'], \n            df['lifeExp'], \n            color='#758D99', \n            alpha=0.1, \n            linewidth=3)\n\n# Plot US and China separately\nax.plot(data[data['country'] == 'United States']['year'], \n        data[data['country'] == 'United States']['lifeExp'], \n        color='#006BA2',\n        linewidth=3)\n\nax.plot(data[data['country'] == 'China']['year'], \n        data[data['country'] == 'China']['lifeExp'], \n        color='#DB444B',\n        linewidth=3)\n\n\nax.plot(data[data['country'] == 'Korea Rep.']['year'], \n        data[data['country'] == 'Korea Rep.']['lifeExp'], \n        color='#3EBCD2',\n        linewidth=3)\n\n\n# y 범위 설정하기\nax.set_ylim(25, 100)\n\n# x 범위 설정하기\nax.set_xlim(1952, 2008)\n\n# 레이블 넣기\nax.text(x=.25, y=.63, s='United States', transform=fig.transFigure, size=10, alpha=.9, color=\"#006BA2\")\nax.text(x=.7, y=.52, s='China', transform=fig.transFigure, size=10, alpha=.9, color=\"#DB444B\")\nax.text(x=.2, y=.45, s='Korea Rep.', transform=fig.transFigure, size=10, alpha=.9, color=\"#3EBCD2\")\n\n\n\n# 타이틀과 서브타이틀 넣기\nax.text(x=0.12, y=.91, s=\"Life Expectation\", transform=fig.transFigure, ha='left', fontsize=13, weight='bold', alpha=.8)\nax.text(x=0.12, y=.86, s=\"Various countries, 1952-2007\", transform=fig.transFigure, ha='left', fontsize=11, alpha=.8)\n\n# 출처 넣기\nax.text(x=0.12, y=0.01, s=\"\"\"Source: \"GAP minder\"\"\", transform=fig.transFigure, ha='left', fontsize=9, alpha=.7)\n\nplt.savefig(\"life_exp.png\")\nplt.show()"
  },
  {
    "objectID": "data_science/posts/AoG_tutorial_01.html",
    "href": "data_science/posts/AoG_tutorial_01.html",
    "title": "Tutorial of Algebra of Graphics",
    "section": "",
    "text": "줄리아 언어에 그래픽 옵션 중 Makie(마키에)라는 패키지가 있습니다. 파이썬의 matplotlib과 같이 그래픽 엔진과 같은 기능을 가지고 있습니다.\nmatplotlib에는 seaborn이 있듯이 Makie에는 Algebra of Graphics라는 패키지가 있습니다. 주로 사용하는 기능을 쉽게 만들 수 있는 기능인데요. grammar of graphics의 영향을 받은 R의 ggplot2와 유사한 기능이 있습니다.\n오늘은 그 튜토리얼을 같이 살펴 보도록 하겠습니다."
  },
  {
    "objectID": "data_science/posts/AoG_tutorial_01.html#팽귄-데이터-셋",
    "href": "data_science/posts/AoG_tutorial_01.html#팽귄-데이터-셋",
    "title": "Tutorial of Algebra of Graphics",
    "section": "팽귄 데이터 셋",
    "text": "팽귄 데이터 셋\n오늘 시각화할 데이터 셋은 팽귄 데이터 셋입니다. 팽귄 333마리에 대한 관측자료입니다. 종, 서식지, 부리(bill) 길이, 부리 깊이, 날개(flipper) 길이, 몸무게, 성별 정보를 가지고 있습니다.\n\n\nCode\nusing PalmerPenguins, DataFrames, CSV\n\npenguins = dropmissing(DataFrame(PalmerPenguins.load()))\nfirst(penguins, 6)\n\n\n6×7 DataFrame\n\n\n\nRow\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\nString15\nString15\nFloat64\nFloat64\nInt64\nInt64\nString7\n\n\n\n\n1\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n\n\n2\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n\n\n3\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181\n3625\nfemale"
  },
  {
    "objectID": "data_science/posts/AoG_tutorial_01.html#숫자-세기",
    "href": "data_science/posts/AoG_tutorial_01.html#숫자-세기",
    "title": "Tutorial of Algebra of Graphics",
    "section": "숫자 세기",
    "text": "숫자 세기\n팽귄 수를 세어 봅니다. AoG(Algebra of Graphics)는 * 기호는 적용을, +는 붙이는 기능을 합니다. data() 함수로 데이터를 가져오고, frequency()는 숫자를 셉니다. mapping()함수는 어떤 기준으로 숫자를 셀지 결정합니다.\n마지막으로 draw 함수를 통해 출력 합니다.\n\n\nCode\nusing AlgebraOfGraphics, CairoMakie\nset_aog_theme!()\n\naxis = (width = 225, height = 225)\npenguin_frequency = data(penguins) * frequency() * mapping(:species)\n\ndraw(penguin_frequency; axis = axis)\n\n\n\n\n\n\n\n\n\n\n색 지정\n여기에 색깔을 지정해 봅니다. 기존에 만든 그래프 penguin_frequency에 새로운 항목을 mapping 함수를 통해 적용합니다.\n\n\nCode\nplt = penguin_frequency * mapping(color = :island)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n\n\n규칙\n덧셈과 곱셈 규칙을 지킵니다.\ndodge argument를 통해 병렬로 제시할 수 있습니다.\n\n\nCode\nplt = penguin_frequency * mapping(color = :island, dodge = :island)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n유사하게 sex로 구분할 수도 있습니다.\n\n\nCode\nplt = penguin_frequency * mapping(color = :island, dodge = :sex)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\nstack을 지정하면 누적그래프를 볼 수 있습니다.\n\n\nCode\nplt = penguin_frequency * mapping(color = :island, stack = :island)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\ndodge와 같이 쓰이면 다음과 같습니다.\n\n\nCode\nplt = penguin_frequency * mapping(color = :island, stack = :island, dodge=:sex)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\nscatter plot은 아래와 같이 만들 수 있습니다.\n\n\nCode\npenguin_bill = data(penguins) * mapping(:bill_length_mm,:bill_depth_mm)\ndraw(penguin_bill; axis = axis)\n\n\n\n\n\n\n\n\n\n함수를 통해 변환하고 이름을 반영할 수도 있습니다.\n\n\nCode\npenguin_bill = data(penguins) * mapping(\n    :bill_length_mm =&gt; (t -&gt; t / 10) =&gt; \"bill length (cm)\",\n    :bill_depth_mm =&gt; (t -&gt; t / 10) =&gt; \"bill depth (cm)\",\n)\ndraw(penguin_bill; axis = axis)\n\n\n\n\n\n\n\n\n\n부리 길이와 깊이에 대한 플롯에 색을 매칭할 수 있습니다.\n\n\nCode\nplt = penguin_bill * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n선형 회귀를 적용하여 그래픽을 적용할 수 있습니다.\n\n\nCode\nplt = penguin_bill * linear() * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n+를 통해 두 그래프를 곂쳐서 출력 할 수 있습니다.\n\n\nCode\nplt = penguin_bill * linear() * mapping(color = :species) + penguin_bill * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n괄호를 써서 다소 긴 코드를 줄일 수 있습니다.\n\n\nCode\nplt = penguin_bill * (linear() + mapping()) * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n또한 아래와 같이 리팩토링도 가능합니다.\n\n\nCode\nlayers = linear() + mapping()\nplt = penguin_bill * layers * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n마커를 지정하여 구분할 수 있습니다.\n\n\nCode\nlayers = linear() + mapping(marker = :sex)\nplt = penguin_bill * layers * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n또는 컬럼을 지정할 수도 있습니다.\n\n\nCode\nlayers = linear() + mapping(col = :sex)\nplt = penguin_bill * layers * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n위의 그래프는 같은 피팅 선형 그래프를 보여주고 있습니다. 데이터와 맞춰서 보여주길 원한다면 아래와 같이 하면 됩니다.\n\n\nCode\nlayers = linear() + mapping()\nplt = penguin_bill * layers * mapping(color = :species, col = :sex)\ndraw(plt; axis = axis)"
  },
  {
    "objectID": "data_science/posts/AoG_tutorial_01.html#density-plot",
    "href": "data_science/posts/AoG_tutorial_01.html#density-plot",
    "title": "Tutorial of Algebra of Graphics",
    "section": "Density plot",
    "text": "Density plot\n밀도 플롯을 그려서 표현 할 수 있습니다.\n\n\nCode\nusing AlgebraOfGraphics: density\nplt = penguin_bill * density(npoints=50) * mapping(col = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\nvisual 함수를 통해 시각적 효과를 지정할 수 있습니다.\n\n\nCode\nplt *= visual(colormap = :grayC, colorrange = (0, 6))\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\nWireframe을 지정하여 3D 그래프로 표현할 수 있습니다.\n\n\nCode\naxis = (type = Axis3, width = 300, height = 300)\nlayer = density() * visual(Wireframe, linewidth=0.05)\nplt = penguin_bill * layer * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\nContour를 구할 수도 있습니다.\n\n\nCode\naxis = (width = 225, height = 225)\nlayer = density() * visual(Contour)\nplt = penguin_bill * layer * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n위에 내용을 합쳐서 아래와 같이 그릴 수도 있습니다.\n\n\nCode\nlayers = density() * visual(Contour) + linear() + mapping()\nplt = penguin_bill * layers * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\nmapping대신 visual 을 사용하여 특성을 지정할 수 도 있습니다.\n\n\nCode\nlayers = density() * visual(Contour) + linear() + visual(alpha = 0.5)\nplt = penguin_bill * layers * mapping(color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n색을 사용해서 3개 변수를 표현하기 할 수 있습니다.\n\n\nCode\nbody_mass = :body_mass_g =&gt; (t -&gt; t / 1000) =&gt; \"body mass (kg)\"\nlayers = linear() * mapping(group = :species) + mapping(color = body_mass, marker = :species)\nplt = penguin_bill * layers\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n혹은 축을 지정하여 3차원으로 표현할 수도 있습니다.\n\n\nCode\naxis = (type = Axis3, width = 300, height = 300)\nplt = penguin_bill * mapping(body_mass, color = :species)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n레이아웃을 지정하여 구분하여 표현도 가능합니다.\n\n\nCode\nplt = penguin_bill * mapping(body_mass, color = :species, layout = :sex)\ndraw(plt; axis = axis)"
  },
  {
    "objectID": "data_science/posts/AoG_tutorial_01.html#머신러닝과-같이-사용하기",
    "href": "data_science/posts/AoG_tutorial_01.html#머신러닝과-같이-사용하기",
    "title": "Tutorial of Algebra of Graphics",
    "section": "머신러닝과 같이 사용하기",
    "text": "머신러닝과 같이 사용하기\n간단히 Decision Tree 모델을 만들어 봅니다.\n\n\nCode\nusing DecisionTree, Random\n\n# use approximately 80% of penguins for training\nRandom.seed!(1234) # for reproducibility\nN = nrow(penguins)\ntrain = fill(false, N)\nperm = randperm(N)\ntrain_idxs = perm[1:floor(Int, 0.8N)]\ntrain[train_idxs] .= true\n\n# fit model on training data and make predictions on the whole dataset\nX = hcat(penguins.bill_length_mm, penguins.bill_depth_mm)\ny = penguins.species\nmodel = DecisionTreeClassifier() # Support-Vector Machine Classifier\nfit!(model, X[train, :], y[train])\nŷ = predict(model, X)\n\n# incorporate relevant information in the dataset\npenguins.train = train;\npenguins.predicted_species = ŷ;\n\n\nCSV.write(\"../data/penguins.csv\", penguins)\n\n\n결과를 보면 Chinstrap종에 대해서 정확도가 낮음을 볼 수 있습니다.\n\n\nCode\npenguins = CSV.read(\"../data/penguins.csv\", DataFrame)\npenguin_bill = data(penguins) * mapping(:bill_length_mm,:bill_depth_mm)\n\naxis = (width = 225, height = 225)\ndataset =:train =&gt; renamer(true =&gt; \"training\", false =&gt; \"testing\") =&gt; \"Dataset\"\naccuracy = (:species, :predicted_species) =&gt; isequal =&gt; \"accuracy\"\nplt = data(penguins) *\n    expectation() *\n    mapping(:species, accuracy) *\n    mapping(col = dataset)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n에러율은 아래와 같이 볼 수 있습니다.\n\n\nCode\nerror_rate = (:species, :predicted_species) =&gt; !isequal =&gt; \"error rate\"\nplt = data(penguins) *\n    expectation() *\n    mapping(:species, error_rate) *\n    mapping(col = dataset)\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n테스트와 트레이닝 기준으로 아래와 같이 분포를 볼 수 있습니다.\n\n\nCode\nprediction = :predicted_species =&gt; \"predicted species\"\ndatalayer = mapping(color = prediction, row = :species, col = dataset)\nplt = penguin_bill * datalayer\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n여기에 모델의 pdf를 곂치면 아래와 같습니다.\n\n\nCode\npdflayer = density() * visual(Contour) * mapping(group = :species, color=:species)\nlayers = pdflayer + datalayer\nplt = penguin_bill * layers\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n단색으로 해당되는 확률만 표현할 수도 있습니다.\n\n\nCode\npdflayer = density() * visual(Contour, colormap=Reverse(:grays)) * mapping(group = :species, row=:species, col = dataset)\nlayers = pdflayer + datalayer\nplt = penguin_bill * layers\ndraw(plt; axis = axis)\n\n\n\n\n\n\n\n\n\n전체를 같이 표현할 수도 있습니다.\n\n\nCode\npdflayer = density() * visual(Contour, colormap=Reverse(:grays)) * mapping(group = :species)\nlayers = pdflayer + datalayer\nplt = penguin_bill * layers\ndraw(plt; axis = axis)"
  },
  {
    "objectID": "data_science/posts/AoG_tutorial_01.html#마무리",
    "href": "data_science/posts/AoG_tutorial_01.html#마무리",
    "title": "Tutorial of Algebra of Graphics",
    "section": "마무리",
    "text": "마무리\n여러가지 그래프를 손쉽게 결합 생성할 수 있어 전처리가 끝난 자료의 EDA를 진행할 때 굉장히 효과적으로 사용할 수 있을 것으로 판단됩니다. 또한 몇가지 규칙을 바탕으로 유연하게 확장 가능한 점도 아주 유용한 부분이라고 생각됩니다."
  },
  {
    "objectID": "data_science/posts/ADP_01.html",
    "href": "data_science/posts/ADP_01.html",
    "title": "ADP 준비 (1)",
    "section": "",
    "text": "ADP는 Advacned Data anlytics Professional의 약자어로 한국데이터산업진흥원에서 운영하는 데이터분석 전문가 자격증입니다.\n\n\nADP는 공공기관에서 운영하지만 부류는 기술사나 기사와 같은 국가자격증이 아닌, 민간자격증으로 분류됩니다. 2016년부터는 국가공인을 받은 민간 자격증으로 변경되었습니다.\n\n\n\n과거 기록을 보면 2019년을 기점으로 접수자와 응시자가 폭발적으로 증가하였습니다. 응시자가 늘어나면서 합격률도 소폭 하락한 것을 볼 수 있는데 시험에 대한 인식이 생겨나면서 이전 보다 많은 사람들이 도전하면서 합격률이 다소 떨어지는 것이 아닐까 추측해 봅니다.\n\n\n\n\n\n\n\n\n\n\n\n\n검정연도\n자격등급\n검정횟수\n접수자수\n응시자수\n취득자수\n합격률\n\n\n2022\n전문가(공인)\n4\n3,525\n2,737\n69\n2.52\n\n\n2021\n전문가(공인)\n4\n3,205\n2,436\n66\n2.71\n\n\n2020\n전문가(공인)\n4\n2,074\n1,664\n32\n1.92\n\n\n2019\n전문가(공인)\n4\n1,516\n1,267\n35\n2.76\n\n\n2018\n전문가(공인)\n4\n585\n501\n18\n3.59\n\n\n2017\n전문가(공인)\n4\n425\n368\n14\n3.8\n\n\n2016\n전문가(공인)\n4\n300\n259\n6\n2.32\n\n\n2015\n전문가\n4\n196\n137\n7\n5.11\n\n\n2014\n전문가\n6\n415\n248\n8\n3.23\n\n\n\n\n\n\nADP는 빅데이터기사와 같은 국가기술자격증은 아님에도 점점 더 많은 사람들이 응시하고 있습니다. 여러가지 이유가 있겠지만, 아주 낮은 홥격률이라는 지점과 데이터 관련한 지식을 보유함을 보여 줄 수 있는 좋은 방법 중 하나로 인식되고 있다고 보고 있습니다.\n특히 취업을 준비하거나 직종을 바꾸고 싶은 사람이 자신의 데이터 역량을 보여주는 방법 중 하나로 고려하는 것으로 추측해 봅니다.\n현업에게는 그리 의미가 크지는 않을 수 있으나 대기업이나 공공기관에서는 국가공인 자격증으로 의의가 있는 것으로 보입니다. 특히 기업 내에서 자신의 역할을 바꾸고자 할 때 유용하게 사용될 수 있다고 생각합니다."
  },
  {
    "objectID": "data_science/posts/ADP_01.html#데이터-분석-관련한-자격증",
    "href": "data_science/posts/ADP_01.html#데이터-분석-관련한-자격증",
    "title": "ADP 준비 (1)",
    "section": "",
    "text": "ADP는 Advacned Data anlytics Professional의 약자어로 한국데이터산업진흥원에서 운영하는 데이터분석 전문가 자격증입니다.\n\n\nADP는 공공기관에서 운영하지만 부류는 기술사나 기사와 같은 국가자격증이 아닌, 민간자격증으로 분류됩니다. 2016년부터는 국가공인을 받은 민간 자격증으로 변경되었습니다.\n\n\n\n과거 기록을 보면 2019년을 기점으로 접수자와 응시자가 폭발적으로 증가하였습니다. 응시자가 늘어나면서 합격률도 소폭 하락한 것을 볼 수 있는데 시험에 대한 인식이 생겨나면서 이전 보다 많은 사람들이 도전하면서 합격률이 다소 떨어지는 것이 아닐까 추측해 봅니다.\n\n\n\n\n\n\n\n\n\n\n\n\n검정연도\n자격등급\n검정횟수\n접수자수\n응시자수\n취득자수\n합격률\n\n\n2022\n전문가(공인)\n4\n3,525\n2,737\n69\n2.52\n\n\n2021\n전문가(공인)\n4\n3,205\n2,436\n66\n2.71\n\n\n2020\n전문가(공인)\n4\n2,074\n1,664\n32\n1.92\n\n\n2019\n전문가(공인)\n4\n1,516\n1,267\n35\n2.76\n\n\n2018\n전문가(공인)\n4\n585\n501\n18\n3.59\n\n\n2017\n전문가(공인)\n4\n425\n368\n14\n3.8\n\n\n2016\n전문가(공인)\n4\n300\n259\n6\n2.32\n\n\n2015\n전문가\n4\n196\n137\n7\n5.11\n\n\n2014\n전문가\n6\n415\n248\n8\n3.23\n\n\n\n\n\n\nADP는 빅데이터기사와 같은 국가기술자격증은 아님에도 점점 더 많은 사람들이 응시하고 있습니다. 여러가지 이유가 있겠지만, 아주 낮은 홥격률이라는 지점과 데이터 관련한 지식을 보유함을 보여 줄 수 있는 좋은 방법 중 하나로 인식되고 있다고 보고 있습니다.\n특히 취업을 준비하거나 직종을 바꾸고 싶은 사람이 자신의 데이터 역량을 보여주는 방법 중 하나로 고려하는 것으로 추측해 봅니다.\n현업에게는 그리 의미가 크지는 않을 수 있으나 대기업이나 공공기관에서는 국가공인 자격증으로 의의가 있는 것으로 보입니다. 특히 기업 내에서 자신의 역할을 바꾸고자 할 때 유용하게 사용될 수 있다고 생각합니다."
  },
  {
    "objectID": "data_science/posts/ADP_01.html#응시-방법",
    "href": "data_science/posts/ADP_01.html#응시-방법",
    "title": "ADP 준비 (1)",
    "section": "응시 방법",
    "text": "응시 방법\n시험은 필기와 실기로 구성되어 있으며, 각각 연 2회 진행됩니다. 필기를 합격한 사람만 실기에 지원할 수 있는 방식으로 2024년 부터는 필기 결과 발표날에 실기시험 모집이 시작됩니다. 시험일시 약 2개월 전에 등록을 할 수 있고 결과 발표까지 한달여 시간이 소요되어 최소 5개월 정도 소요된다고 볼 수 있습니다.\n\n필기시험의 범위\n시험범위는 유료로 판매되고 있는 가이드북을 통해 확인할 수 있습니다. 홈페이지에서는 아래와 같은 목차를 안내하고 있습니다.\n\n데이터 이해\n\n데이터의 이해\n\n데이터와 정보\n데이터베이스의 정의와 특징\n데이터베이스 활용\n\n데이터의 가치와 미래\n\n빅데이터의 이해\n빅데이터의 가치와 영향\n비즈니스 모델\n위기 요인과 통제 방안\n미래의 빅데이터\n\n가치 창조를 위한 데이터 사이언스와 전략 인사이트\n\n빅데이터분석과 전략 인사이트\n전략 인사이트 도출을 위한 필요 역량\n빅데이터 그리고 데이터 사이언스의 미래\n\n\n데이터 처리 기술 이해\n\n데이터 처리 프로세스\n\nETL(Extraction, Transformation and Load)\nCDC(Change Data Capture)\nEAI(Enterprise Application Integration)\n데이터 연계 및 통합 기법 요약\n대용량 비정형 데이터 처리\n\n데이터 처리 기술\n\n분산 데이터 저장 기술\n분산 컴퓨팅 기술\n클라우드 인프라 기술\n\n\n데이터분석 기획\n\n데이터분석 기획의 이해\n\n분석 기획 방향성 도출\n분석 방법론\n분석 과제 발굴\n분석 프로젝트 관리 방안\n\n분석 마스터 플랜\n\n마스터 플랜 수립\n분석 거버넌스 체계 수립\n\n\n데이터분석\n\nR기초와 데이터 마트\n\nR기초\n데이터 마트\n결측값 처리와 이상값 검색\n\n통계분석\n\n통계학 개론\n기초 통계분석\n다변량 분석\n시계열 예측\n\n정형 데이터 마이닝\n\n데이터 마이닝 개요\n분류분석(Classification)\n군집분석(Clustering)\n연관분석(Association Analysis)\n\n비정형 데이터 마이닝\n\n텍스트 마이닝\n사회연결망 분석\n\n\n데이터 시각화\n\n시각화 인사이트 프로세스\n\n시각화 인사이트 프로세스의 의미\n탐색(1단계)\n분석(2단계)\n활용(3단계)\n\n시각화 디자인\n\n시각화의 정의\n시각화 프로세스\n시각화 방법\n빅데이터와 시각화 디자인\n\n시각화 구현\n\n시각화 구현 개요\n분석 도구를 이용한 시각화 구현\n라이브러리 기반의 시각화 구현: D3.js\n\n\n\n\n\n실기시험의 범위\n실기 시험은 범위를 지정하고 있지 않으나 크게 머신러닝과 통계라는 구분으로 문제가 구성되어 있습니다. 시험에서 다루는 범주가 모호하기 때문에 준비하는 것이 상당히 막막한 시험입니다. 또한 시험 합격률도 낮아 시험 보는 것이 돈이 아깝게 느껴질 때가 있습니다.\n실기시험을 준비해 나가면서 정리한 내용을 게시 하겠습니다."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "데이터 과학에 관련된 코드와 지식을 공유하고자 합니다. 데이터를 통한 의사결정에 관심이 많습니다."
  },
  {
    "objectID": "data_science/posts/ADP_02.html",
    "href": "data_science/posts/ADP_02.html",
    "title": "ADP 준비 (2) : 탐색적 데이터 분석(EDA)",
    "section": "",
    "text": "탐색적 데이터 분석(EDA)은 데이터 세트를 주의 깊게 조사하고, 그 안에서 패턴, 이상치, 기본 구조를 탐색하여 데이터의 특성과 내재된 관계를 이해하는 과정입니다. EDA는 통계적 그래픽과 요약 통계를 활용해 데이터를 시각적으로 검토하는 것을 포함하며, 데이터 과학 프로젝트의 초기 단계에서 매우 중요한 역할을 합니다.\n\n\n탐색적 데이터 분석은 데이터 과학자와 분석가가 데이터를 깊이 이해하고, 효과적인 분석 전략을 수립하며, 데이터 기반 의사 결정을 내리는 데 있어 핵심적인 과정입니다. EDA는 데이터의 질적인 면모를 파악하고, 분석 준비 과정에서 발생할 수 있는 문제를 사전에 식별하며 해결책을 모색하는 데 도움을 줍니다. 따라서, 모든 데이터 분석 프로젝트에서 EDA에 충분한 시간과 노력을 투자하는 것이 중요합니다.\n\n\n\nThe Datasaurus Dozen\n\n\n데이터 이해: 데이터의 분포, 중심 경향성, 변이도 등을 파악함으로써 데이터 분석 전략을 수립하는 데 필수적입니다. 예를 들어, 시애틀 지역의 평균 연봉을 조사할 때, 빌 게이츠와 같은 이상치를 고려하지 않으면 평균값이 실제보다 과대평가될 수 있습니다. 이런 문제를 방지하기 위해 EDA를 통한 데이터의 깊은 이해가 필요합니다.\n패턴 및 관계 발견: 데이터 내 숨겨진 패턴과 관계를 발견하는 것은 데이터 기반 의사 결정에 있어 필수적입니다. ‘The Datasaurus Dozen’ 예시처럼, 동일한 통계 요약이라도 데이터 간에 명확한 패턴 차이가 있을 수 있으며, 이는 시각적 탐색 없이는 발견하기 어렵습니다. 이는 EDA가 단순한 요약 통계를 넘어선 깊은 데이터 이해를 가능하게 한다는 것을 보여줍니다.\n데이터 정제 및 전처리: EDA를 통해 데이터의 결측치, 극단치, 이상치 등 문제점을 식별하고, 이를 어떻게 처리할지에 대한 전략을 세울 수 있습니다. 이 과정은 데이터 분석의 정확성을 높이고, 품질을 향상시키는 데 필수적입니다.\n\n\n\n탐색적 데이터 분석(EDA)에는 정해진 방법은 없으며, 데이터의 특성과 분석 목적에 따라 다양한 접근을 할 수 있습니다. 일반적으로, EDA는 통계적 요약과 데이터 시각화의 두 가지 방법을 중심으로 진행됩니다.\n\n\n데이터의 기본적인 특성을 파악하기 위해 중앙값, 평균, 최대값, 최소값, 결측치 수와 같은 기본적인 통계값을 확인합니다. 이는 데이터의 전반적인 계량적 특성을 이해하는 데 도움이 됩니다. 또한, 분산, 표준편차, 사분위수 등을 통해 데이터의 분포와 변동성을 평가할 수 있습니다.\n\n\n\n데이터 시각화는 EDA의 가장 강력한 도구 중 하나입니다. 복잡한 데이터 세트에서 패턴, 이상치, 관계를 직관적으로 식별 할 수 있습니다.\n히스토그램: 데이터의 분포를 이해하는 데 유용하며, 각 데이터 포인트가 속하는 구간의 빈도를 표현합니다. 히스토그램을 통해 데이터의 중심 경향성, 분산, 그리고 이상치의 존재 유무를 빠르게 파악할 수 있습니다. 산포도(Scatter Plot): 두 변수 간의 관계를 시각적으로 표현합니다. 데이터 포인트들이 어떻게 분포하는지, 두 변수 사이에 상관 관계가 있는지를 살펴볼 수 있습니다. 박스 플롯(Box Plot): 데이터의 중앙값, 사분위수, 이상치 등을 시각적으로 표현하는 데 유용합니다. 박스 플롯을 통해 데이터의 분포와 이상치를 한눈에 파악할 수 있습니다. 히트맵(Heatmap): 두 변수 간의 상관관계나, 데이터의 밀도 등을 색상의 강도로 표현합니다. 복잡한 관계나 패턴을 시각적으로 쉽게 이해할 수 있게 합니다."
  },
  {
    "objectID": "data_science/posts/ADP_02.html#탐색적-데이터-분석이란",
    "href": "data_science/posts/ADP_02.html#탐색적-데이터-분석이란",
    "title": "ADP 준비 (2) : 탐색적 데이터 분석(EDA)",
    "section": "",
    "text": "탐색적 데이터 분석(EDA)은 데이터 세트를 주의 깊게 조사하고, 그 안에서 패턴, 이상치, 기본 구조를 탐색하여 데이터의 특성과 내재된 관계를 이해하는 과정입니다. EDA는 통계적 그래픽과 요약 통계를 활용해 데이터를 시각적으로 검토하는 것을 포함하며, 데이터 과학 프로젝트의 초기 단계에서 매우 중요한 역할을 합니다.\n\n\n탐색적 데이터 분석은 데이터 과학자와 분석가가 데이터를 깊이 이해하고, 효과적인 분석 전략을 수립하며, 데이터 기반 의사 결정을 내리는 데 있어 핵심적인 과정입니다. EDA는 데이터의 질적인 면모를 파악하고, 분석 준비 과정에서 발생할 수 있는 문제를 사전에 식별하며 해결책을 모색하는 데 도움을 줍니다. 따라서, 모든 데이터 분석 프로젝트에서 EDA에 충분한 시간과 노력을 투자하는 것이 중요합니다.\n\n\n\nThe Datasaurus Dozen\n\n\n데이터 이해: 데이터의 분포, 중심 경향성, 변이도 등을 파악함으로써 데이터 분석 전략을 수립하는 데 필수적입니다. 예를 들어, 시애틀 지역의 평균 연봉을 조사할 때, 빌 게이츠와 같은 이상치를 고려하지 않으면 평균값이 실제보다 과대평가될 수 있습니다. 이런 문제를 방지하기 위해 EDA를 통한 데이터의 깊은 이해가 필요합니다.\n패턴 및 관계 발견: 데이터 내 숨겨진 패턴과 관계를 발견하는 것은 데이터 기반 의사 결정에 있어 필수적입니다. ‘The Datasaurus Dozen’ 예시처럼, 동일한 통계 요약이라도 데이터 간에 명확한 패턴 차이가 있을 수 있으며, 이는 시각적 탐색 없이는 발견하기 어렵습니다. 이는 EDA가 단순한 요약 통계를 넘어선 깊은 데이터 이해를 가능하게 한다는 것을 보여줍니다.\n데이터 정제 및 전처리: EDA를 통해 데이터의 결측치, 극단치, 이상치 등 문제점을 식별하고, 이를 어떻게 처리할지에 대한 전략을 세울 수 있습니다. 이 과정은 데이터 분석의 정확성을 높이고, 품질을 향상시키는 데 필수적입니다.\n\n\n\n탐색적 데이터 분석(EDA)에는 정해진 방법은 없으며, 데이터의 특성과 분석 목적에 따라 다양한 접근을 할 수 있습니다. 일반적으로, EDA는 통계적 요약과 데이터 시각화의 두 가지 방법을 중심으로 진행됩니다.\n\n\n데이터의 기본적인 특성을 파악하기 위해 중앙값, 평균, 최대값, 최소값, 결측치 수와 같은 기본적인 통계값을 확인합니다. 이는 데이터의 전반적인 계량적 특성을 이해하는 데 도움이 됩니다. 또한, 분산, 표준편차, 사분위수 등을 통해 데이터의 분포와 변동성을 평가할 수 있습니다.\n\n\n\n데이터 시각화는 EDA의 가장 강력한 도구 중 하나입니다. 복잡한 데이터 세트에서 패턴, 이상치, 관계를 직관적으로 식별 할 수 있습니다.\n히스토그램: 데이터의 분포를 이해하는 데 유용하며, 각 데이터 포인트가 속하는 구간의 빈도를 표현합니다. 히스토그램을 통해 데이터의 중심 경향성, 분산, 그리고 이상치의 존재 유무를 빠르게 파악할 수 있습니다. 산포도(Scatter Plot): 두 변수 간의 관계를 시각적으로 표현합니다. 데이터 포인트들이 어떻게 분포하는지, 두 변수 사이에 상관 관계가 있는지를 살펴볼 수 있습니다. 박스 플롯(Box Plot): 데이터의 중앙값, 사분위수, 이상치 등을 시각적으로 표현하는 데 유용합니다. 박스 플롯을 통해 데이터의 분포와 이상치를 한눈에 파악할 수 있습니다. 히트맵(Heatmap): 두 변수 간의 상관관계나, 데이터의 밀도 등을 색상의 강도로 표현합니다. 복잡한 관계나 패턴을 시각적으로 쉽게 이해할 수 있게 합니다."
  },
  {
    "objectID": "data_science/posts/ADP_02.html#데이터-eda-진행하기",
    "href": "data_science/posts/ADP_02.html#데이터-eda-진행하기",
    "title": "ADP 준비 (2) : 탐색적 데이터 분석(EDA)",
    "section": "데이터 EDA 진행하기",
    "text": "데이터 EDA 진행하기\n\n데이터 불러오기\nEDA를 직접 수행하기 위해, 우선적으로 데이터를 불러옵니다. 본 예제에서는 Datamanin에서 공유한 ADP 29회 대구도시공사의 영구임대아파트 입주자 퇴거여부 데이터를 사용합니다. 이 데이터 세트는 고유번호를 가진 계약자와 특정 아파트에 대한 매년 퇴거여부를 기록한 것으로, 주거 정책 분석이나 도시 계획 연구에 유용할 수 있는 정보를 담고 있습니다.\n\nimport pandas as pd\ndata = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/adp/29/p1.csv\", encoding=\"cp949\")\nprint(data.shape)\n\n(86904, 23)\n\n\npandas 라이브러리를 사용하여 데이터를 성공적으로 불러왔으며, 데이터는 총 23개의 컬럼과 86,904개의 레코드로 구성되어 있습니다. 이는 분석 준비 과정에서 데이터의 규모와 구조를 빠르게 파악할 수 있게 합니다.\n\n\n자료형 파악하기\n데이터의 자료형을 파악하는 것은 분석 방향을 설정하고 적절한 데이터 전처리 계획을 수립하는 데 중요합니다. pandas에서 제공하는 info() 메소드를 사용하면 각 컬럼의 데이터 타입과 결측치 여부를 쉽게 확인할 수 있습니다.\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 86904 entries, 0 to 86903\nData columns (total 23 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   순번       86904 non-null  int64  \n 1   계약구분     86396 non-null  object \n 2   재계약횟수    86904 non-null  int64  \n 3   거주개월     86904 non-null  int64  \n 4   아파트 이름   86904 non-null  object \n 5   아파트 ID   86904 non-null  int64  \n 6   아파트 평점   85679 non-null  float64\n 7   호실고유번호   86904 non-null  int64  \n 8   층        86904 non-null  int64  \n 9   평형대      86904 non-null  int64  \n 10  계약자고유번호  86904 non-null  int64  \n 11  계약서고유번호  86904 non-null  int64  \n 12  입주연도     86904 non-null  int64  \n 13  퇴거연도     25762 non-null  float64\n 14  거주연도     86904 non-null  int64  \n 15  월세(원)    86904 non-null  int64  \n 16  보증금(원)   86904 non-null  int64  \n 17  대표나이     86904 non-null  int64  \n 18  나이       86904 non-null  int64  \n 19  성별       86904 non-null  object \n 20  결혼여부     86904 non-null  object \n 21  거주자 수    86904 non-null  int64  \n 22  퇴거여부     86904 non-null  object \ndtypes: float64(2), int64(16), object(5)\nmemory usage: 15.2+ MB\n\n\n이 명령어를 실행하면, 각 컬럼별로 데이터 타입(float64, int64, object, datetime64 등)이 어떻게 되는지, 그리고 비어 있지 않은 값의 수가 몇 개인지를 알 수 있습니다. 이를 통해 어떤 컬럼이 수치형 데이터를 담고 있는지, 어떤 컬럼이 범주형 데이터나 날짜 정보를 포함하는지 파악할 수 있습니다. 또한, 결측치가 있는 컬럼을 식별하고, 이를 처리하기 위한 전략을 세울 수 있습니다.\n\n\n각 컬럼의 통계값 확인하기\n데이터의 다양한 특성을 깊이 이해하기 위해, pandas의 describe 메소드를 사용하여 각 컬럼의 기초 통계량을 확인합니다. 이 메소드는 평균(mean), 중앙값(50%), 표준편차(std), 최소값(min), 최대값(max) 등 숫자형 자료의 주요 통계량을 제공합니다.\n\nsummary = data.describe()\nsummary\n\n\n\n\n\n\n\n\n순번\n재계약횟수\n거주개월\n아파트 ID\n아파트 평점\n호실고유번호\n층\n평형대\n계약자고유번호\n계약서고유번호\n입주연도\n퇴거연도\n거주연도\n월세(원)\n보증금(원)\n대표나이\n나이\n거주자 수\n\n\n\n\ncount\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n85679.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n25762.000000\n86904.000000\n86904.000000\n8.690400e+04\n86904.000000\n86904.000000\n86904.000000\n\n\nmean\n6491.167507\n7.381709\n174.413318\n1.830295\n6.393294\n43444.813633\n7.881202\n13.289388\n43447.639257\n43447.678220\n2005.240127\n2015.992237\n2013.990150\n57680.561309\n3.384638e+06\n66.673893\n59.664043\n1.652536\n\n\nstd\n3745.003081\n2.759457\n64.811846\n0.874843\n1.284757\n25088.009930\n4.267868\n2.385220\n25087.616670\n25087.498178\n4.834619\n3.144036\n3.729721\n30588.513118\n2.381399e+06\n12.949539\n13.275218\n0.926899\n\n\nmin\n1.000000\n1.000000\n1.000000\n1.000000\n5.000000\n1.000000\n1.000000\n12.000000\n1.000000\n1.000000\n1994.000000\n2008.000000\n2008.000000\n31300.000000\n1.520000e+06\n21.000000\n20.000000\n1.000000\n\n\n25%\n3241.000000\n5.000000\n126.000000\n1.000000\n5.000000\n21724.000000\n4.000000\n12.000000\n21721.000000\n21724.000000\n2002.000000\n2014.000000\n2011.000000\n40300.000000\n1.954000e+06\n59.000000\n51.000000\n1.000000\n\n\n50%\n6547.000000\n8.000000\n197.000000\n2.000000\n7.000000\n43425.000000\n8.000000\n12.000000\n43446.000000\n43451.000000\n2003.000000\n2017.000000\n2014.000000\n43600.000000\n2.144000e+06\n66.000000\n59.000000\n1.000000\n\n\n75%\n9711.250000\n10.000000\n222.000000\n2.000000\n7.000000\n65170.000000\n12.000000\n15.000000\n65175.000000\n65178.000000\n2008.000000\n2019.000000\n2017.000000\n62900.000000\n3.778000e+06\n76.000000\n69.000000\n2.000000\n\n\nmax\n12883.000000\n12.000000\n323.000000\n5.000000\n10.000000\n86891.000000\n15.000000\n19.000000\n86892.000000\n86904.000000\n2020.000000\n2020.000000\n2020.000000\n311080.000000\n2.078400e+07\n121.000000\n120.000000\n10.000000\n\n\n\n\n\n\n\n이 데이터로부터, 각 변수의 분포가 어떻게 되는지, 이상치가 존재하는지, 데이터가 얼마나 쏠려 있는지(왜도) 등을 파악할 수 있습니다. 특히, 중앙값과 평균의 차이를 분석함으로써 데이터 분포의 비대칭성을 탐색할 수 있습니다.\n\nvalues = (summary.loc[\"50%\"] - summary.loc[\"mean\"]).abs()  # 중간값과 평균 차이의 절대값\nsorted_columns = (values/summary.loc[\"mean\"]).sort_values(ascending=False).index # 평균으로 나누어 정규화\n\nsummary[sorted_columns]\n\n\n\n\n\n\n\n\n거주자 수\n보증금(원)\n월세(원)\n거주개월\n평형대\n아파트 평점\n아파트 ID\n재계약횟수\n층\n나이\n대표나이\n순번\n입주연도\n퇴거연도\n호실고유번호\n계약서고유번호\n계약자고유번호\n거주연도\n\n\n\n\ncount\n86904.000000\n8.690400e+04\n86904.000000\n86904.000000\n86904.000000\n85679.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n25762.000000\n86904.000000\n86904.000000\n86904.000000\n86904.000000\n\n\nmean\n1.652536\n3.384638e+06\n57680.561309\n174.413318\n13.289388\n6.393294\n1.830295\n7.381709\n7.881202\n59.664043\n66.673893\n6491.167507\n2005.240127\n2015.992237\n43444.813633\n43447.678220\n43447.639257\n2013.990150\n\n\nstd\n0.926899\n2.381399e+06\n30588.513118\n64.811846\n2.385220\n1.284757\n0.874843\n2.759457\n4.267868\n13.275218\n12.949539\n3745.003081\n4.834619\n3.144036\n25088.009930\n25087.498178\n25087.616670\n3.729721\n\n\nmin\n1.000000\n1.520000e+06\n31300.000000\n1.000000\n12.000000\n5.000000\n1.000000\n1.000000\n1.000000\n20.000000\n21.000000\n1.000000\n1994.000000\n2008.000000\n1.000000\n1.000000\n1.000000\n2008.000000\n\n\n25%\n1.000000\n1.954000e+06\n40300.000000\n126.000000\n12.000000\n5.000000\n1.000000\n5.000000\n4.000000\n51.000000\n59.000000\n3241.000000\n2002.000000\n2014.000000\n21724.000000\n21724.000000\n21721.000000\n2011.000000\n\n\n50%\n1.000000\n2.144000e+06\n43600.000000\n197.000000\n12.000000\n7.000000\n2.000000\n8.000000\n8.000000\n59.000000\n66.000000\n6547.000000\n2003.000000\n2017.000000\n43425.000000\n43451.000000\n43446.000000\n2014.000000\n\n\n75%\n2.000000\n3.778000e+06\n62900.000000\n222.000000\n15.000000\n7.000000\n2.000000\n10.000000\n12.000000\n69.000000\n76.000000\n9711.250000\n2008.000000\n2019.000000\n65170.000000\n65178.000000\n65175.000000\n2017.000000\n\n\nmax\n10.000000\n2.078400e+07\n311080.000000\n323.000000\n19.000000\n10.000000\n5.000000\n12.000000\n15.000000\n120.000000\n121.000000\n12883.000000\n2020.000000\n2020.000000\n86891.000000\n86904.000000\n86892.000000\n2020.000000\n\n\n\n\n\n\n\n거주자 수와 보증금, 월세, 거주개월 등은 평균과 중간값의 차이가 상대적으로 크다는 걸 알 수 있습니다. 중앙값과 평균의 차이가 상대적으로 큰 변수들을 살펴보면, 이러한 변수들은 데이터가 한쪽으로 쏠려 있음을 나타냅니다. 평균이 중앙값보다 크게 나타나는 경우, 데이터는 오른쪽(높은 값 쪽)으로 쏠려 있음을 의미합니다.\n그럼 이들 값들의 분포를 확인하는 그래프를 그려 보도록 하겠습니다.\n\n\n분포 그려보기\n데이터의 분포를 시각화하는 것은 데이터 분석에서 중요한 단계 중 하나입니다. 분포를 통해 데이터의 전반적인 형태, 중심 경향, 변동성, 그리고 이상치의 존재 여부를 파악할 수 있습니다. 히스토그램은 이러한 분석을 위해 자주사용되는 도구 중 하나로, 데이터를 구간별로 나누어 각 구간에 속하는 데이터 포인트의 수를 막대 그래프로 표현합니다.\nseaborn 라이브러리는 Python에서 데이터 시각화를 위해 자주 사용되며, matplotlib 기반으로 더 다양하고 아름다운 그래픽 옵션을 제공합니다. 다만 한글 폰트 문제를 해결하기 위해 matplotlib의 폰트 설정을 변경해야 합니다.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.rc('font', family='NanumGothic')\nplt.style.use(\"ggplot\")\n\n\n\n\n\n\n\nmatplotlib에서 한글 사용하기\n\n\n\nmatplotlib의 font_manager 모듈을 사용하여 시스템에 설치된 폰트 목록을 확인할 수 있습니다. 아래는 matplotlib에서 사용 가능한 폰트를 확인하는 코드 예시입니다:\n\nfrom matplotlib import font_manager\n\nfont_manager.get_font_names()\n\n\n\n\n\nhistogram을 그려 봅니다.\n데이터 시각화는 복잡한 데이터 세트를 이해하는 데 매우 중요한 도구입니다. 특히 히스토그램은 데이터의 분포, 중심 경향, 변동성을 직관적으로 파악할 수 있게 해주며, 이상치나 데이터의 형태를 식별하는 데 유용합니다.\n\n단일 변수의 분포 시각화하기\n첫 번째 단계로, 우리는 seaborn 라이브러리의 histplot 함수를 사용하여 단일 변수의 분포를 시각화할 수 있습니다. 예를 들어, ‘거주자 수’ 데이터의 분포를 살펴보겠습니다:\n\nsns.histplot(data=data, x=\"거주자 수\")\nplt.show()\n\n\n\n\n\n\n\n\n이 히스토그램은 ’거주자 수’의 분포를 보여줍니다. 각 막대는 데이터의 구간을 나타내며, 막대의 높이는 해당 구간에 속하는 데이터 포인트의 수를 나타냅니다.\n\n\n이산 데이터 시각화\n데이터가 이산적인 값을 가질 경우, bins 파라미터를 지정하여 분포를 더 명확하게 표현할 수 있습니다. 이는 데이터를 특정 수의 구간으로 나누어 각 구간의 빈도를 보다 명확하게 시각화합니다\n\nsns.histplot(data=data, x=\"거주자 수\", bins=10)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n여러 컬럼 동시에 시각화하기\n데이터 세트에 있는 여러 변수의 분포를 동시에 시각화하려면, matplotlib의 subplots를 사용하여 여러 그래프를 배열할 수 있습니다. 이 방법은 데이터의 다양한 측면을 한눈에 비교하고 분석할 수 있게 해줍니다.\n\nn = len(data.columns)\nncols = 4  # 열의 수를 지정합니다.\nnrows = n//ncols + (0 if n%ncols == 0 else 1) #row 갯수를 정합니다. 딱 떨어지지 않으면 1줄을 더 추가합니다.\nfig, axes = plt.subplots(nrows, ncols, figsize=(8, 8))   \nfor i, column in enumerate(data.columns):\n  row, col = divmod(i, ncols)   # 위치를 잡습니다.\n  sns.histplot(data=data, x=column, ax=axes[row][col])\n  \nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n상관관계를 파악해 보기\n데이터 분석에서 수치형 데이터 간의 상관관계를 파악하는 것은 변수들 사이의 관계를 이해하고, 잠재적인 인사이트를 발견하는데 중요한 사항 중 하나입니다. 상관관계 분석을 통해 두 변수 간의 연관성의 강도와 방향을 확인할 수 있으며, 이는 향후 분석 방향성을 제시하거나 예측 모델을 구축하는 데 유용한 정보를 제공합니다.\n\n수치형 데이터 필터링\n분석을 시작하기 전에, 수치형 데이터만을 포함하는 데이터프레임을 생성합니다. 이는 pandas의 select_dtypes 메소드를 사용하여 쉽게 수행할 수 있습니다:\n\nnumber_data = data.select_dtypes(include=[\"number\", \"datetime\"])\nnumber_data.head()\n\n\n\n\n\n\n\n\n순번\n재계약횟수\n거주개월\n아파트 ID\n아파트 평점\n호실고유번호\n층\n평형대\n계약자고유번호\n계약서고유번호\n입주연도\n퇴거연도\n거주연도\n월세(원)\n보증금(원)\n대표나이\n나이\n거주자 수\n\n\n\n\n0\n1\n10\n222\n5\n7.0\n14520\n1\n12\n15468\n15865\n2003\nNaN\n2008\n47100\n3646000\n46\n33\n3\n\n\n1\n1\n10\n222\n5\n7.0\n14520\n1\n12\n15468\n15865\n2003\nNaN\n2009\n56500\n4375000\n46\n34\n3\n\n\n2\n1\n10\n222\n5\n7.0\n14520\n1\n12\n15468\n15865\n2003\nNaN\n2010\n56500\n4375000\n46\n35\n3\n\n\n3\n1\n10\n222\n5\n7.0\n14520\n1\n12\n15468\n15865\n2003\nNaN\n2011\n69900\n5408000\n46\n36\n3\n\n\n4\n1\n10\n222\n5\n7.0\n14520\n1\n12\n15468\n15865\n2003\nNaN\n2012\n69900\n5408000\n46\n37\n3\n\n\n\n\n\n\n\n\n\n의미 없는 수치 데이터 제거\n분석에 앞서, 데이터에 포함된 일부 수치는 분석이 필요하지 않는 데이터가 있습니다. 예를 들어, 아이디와 같은 식별자는 수치형 데이터이지만 상관관계 분석에는 적합하지 않습니다. 이러한 컬럼을 데이터프레임에서 제거합니다:\n\nnumber_data = number_data.drop(['아파트 ID', '호실고유번호', '계약자고유번호', '계약서고유번호'], axis=1)\n\n\n\n상관관계 계산하기\nDataFrame의 corr 메소드를 사용하여 수치형 데이터 간의 상관관계를 쉽게 계산할 수 있습니다. 이 메소드는 각 변수 쌍 사이의 상관계수를 계산하여, 변수 간의 선형적 관계의 강도와 방향을 나타냅니다:\n\ncorr_matrix = number_data.corr()\nprint(corr_matrix)\n\n              순번     재계약횟수      거주개월    아파트 평점         층       평형대      입주연도  \\\n순번      1.000000  0.064347  0.020264  0.669002  0.017053  0.071388 -0.003963   \n재계약횟수   0.064347  1.000000  0.942340  0.094593  0.003765  0.058462 -0.766560   \n거주개월    0.020264  0.942340  1.000000  0.035440  0.010561  0.055917 -0.846649   \n아파트 평점  0.669002  0.094593  0.035440  1.000000 -0.014835  0.136416 -0.016888   \n층       0.017053  0.003765  0.010561 -0.014835  1.000000 -0.003880 -0.008084   \n평형대     0.071388  0.058462  0.055917  0.136416 -0.003880  1.000000 -0.039263   \n입주연도   -0.003963 -0.766560 -0.846649 -0.016888 -0.008084 -0.039263  1.000000   \n퇴거연도   -0.048212  0.507212  0.508846 -0.035515 -0.005996  0.016107  0.167870   \n거주연도    0.002008 -0.089866 -0.110160  0.000813  0.000889  0.000209  0.342594   \n월세(원)   0.043362  0.234081  0.241858  0.119941  0.044420  0.387430 -0.225347   \n보증금(원)  0.014752  0.267571  0.259088  0.082025  0.018159  0.311986 -0.251460   \n대표나이    0.040838  0.212901  0.197168  0.028216 -0.054120 -0.031003 -0.202540   \n나이      0.040400  0.182430  0.161381  0.027753 -0.052542 -0.030184 -0.101318   \n거주자 수   0.021180 -0.101500 -0.065216  0.046848  0.012708  0.305857 -0.021285   \n\n            퇴거연도      거주연도     월세(원)    보증금(원)      대표나이        나이     거주자 수  \n순번     -0.048212  0.002008  0.043362  0.014752  0.040838  0.040400  0.021180  \n재계약횟수   0.507212 -0.089866  0.234081  0.267571  0.212901  0.182430 -0.101500  \n거주개월    0.508846 -0.110160  0.241858  0.259088  0.197168  0.161381 -0.065216  \n아파트 평점 -0.035515  0.000813  0.119941  0.082025  0.028216  0.027753  0.046848  \n층      -0.005996  0.000889  0.044420  0.018159 -0.054120 -0.052542  0.012708  \n평형대     0.016107  0.000209  0.387430  0.311986 -0.031003 -0.030184  0.305857  \n입주연도    0.167870  0.342594 -0.225347 -0.251460 -0.202540 -0.101318 -0.021285  \n퇴거연도    1.000000  0.544507  0.122154  0.109997 -0.040554  0.076886 -0.090187  \n거주연도    0.544507  1.000000  0.207519  0.172206 -0.055592  0.226726 -0.065814  \n월세(원)   0.122154  0.207519  1.000000  0.973427  0.045634  0.102818  0.157934  \n보증금(원)  0.109997  0.172206  0.973427  1.000000  0.053073  0.100153  0.131163  \n대표나이   -0.040554 -0.055592  0.045634  0.053073  1.000000  0.959848 -0.160751  \n나이      0.076886  0.226726  0.102818  0.100153  0.959848  1.000000 -0.175297  \n거주자 수  -0.090187 -0.065814  0.157934  0.131163 -0.160751 -0.175297  1.000000  \n\n\n\n\n상관관계 결과 해석하기\n상관계수는 -1에서 1 사이의 값을 가지며, 값이 클수록 두 변수 사이에 강한 양의 선형 관계가, 값이 작을수록 강한 음의 선형 관계가 있음을 의미합니다. 0에 가까운 값은 두 변수 사이에 선형 관계가 거의 없음을 나타냅니다.\n상관관계 분석을 통해 우리는 데이터 내 변수들 간의 관계를 파악하고, 이를 바탕으로 더 깊은 데이터 분석을 진행할 수 있습니다. 예를 들어, 높은 상관관계를 가진 변수들을 발견하면, 이 변수들이 비슷한 정보를 담고 있거나 서로 영향을 미치고 있을 가능성을 고려할 수 있습니다. 이러한 인사이트는 향후 분석 방향을 결정하거나, 데이터 모델링에 있어 중요한 변수를 선택하는 데 도움을 줄 수 있습니다.\n\n\n상관관계 시각화하기: Heatmap 사용법\n상관관계 분석 결과를 시각화하는 가장 효과적인 방법 중 하나는 heatmap을 사용하는 것입니다. seaborn 라이브러리의 heatmap 함수를 통해, 데이터프레임의 상관계수 매트릭스를 색상의 강도로 나타낼 수 있으며, 이는 분석 결과를 직관적으로 이해할 수 있게 합니다.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 상관계수 매트릭스를 Heatmap으로 시각화\n\nsns.heatmap(number_data.corr(), cmap='coolwarm', annot=True, fmt=\".2f\", vmin=-1, vmax=1)\nplt.show()\n\nC:\\Users\\freed\\.pyenv\\pyenv-win\\versions\\3.10.1\\lib\\site-packages\\seaborn\\utils.py:80: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.canvas.draw()\nC:\\Users\\freed\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\pylabtools.py:152: UserWarning: Glyph 8722 (\\N{MINUS SIGN}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\n주요 발견 사항\n\n재계약 횟수와 거주개월, 월세와 보증금, 대표나이와 나이 사이에는 아주 강한 선형적 상관관계가 있습니다. 이러한 높은 상관관계는 변수들이 서로 밀접하게 연결되어 있음을 나타냅니다. 특히, 다중공선성 문제를 고려할 때, 이러한 변수들은 통계 모델에서 주의 깊게 다뤄야 합니다.\n입주연도와 재계약횟수, 거주개월 사이의 음의 상관관계는 입주 연도가 최근일수록 재계약 횟수와 거주 개월이 적다는 것을 의미할 수 있습니다. 이는 새로운 아파트가 시장에 나오면서 발생하는 자연스러운 현상일 수 있습니다.\n평형대와 거주자 수, 월세와 보증금 사이의 양의 상관관계는 큰 평수의 아파트에 거주자 수가 많고, 월세와 보증금이 높게 설정되는 경향을 보여줍니다. 이는 시장의 일반적인 기대와 일치합니다.\n\n\n\n분석의 한계와 주의사항\n상관관계 분석은 변수들 사이의 선형적 관계의 강도를 나타내지만, 인과관계를 설명하지는 않습니다. 따라서 상관관계가 높다고 해서 한 변수의 변화가 다른 변수의 변화를 직접적으로 초래한다고 해석해서는 안 됩니다.\nheatmap을 통한 상관관계 시각화는 데이터 내 변수들 간의 관계를 한눈에 파악할 수 있게 해줍니다. 이러한 분석을 통해 얻은 인사이트는 데이터를 더 깊게 이해하고, 향후 분석이나 모델링에 있어 중요한 변수를 선정하는 데 도움을 줄 수 있습니다. 특히, 의외의 상관관계를 발견했다면, 이를 근거로 추가적인 분석을 수행하여 데이터의 숨겨진 패턴이나 인사이트를 발견할 수 있습니다.\n\n\n\n산포도로 데이터 관계 탐색하기\n데이터 분석에서 산포도는 두 변수 간의 관계를 시각적으로 파악하는 강력한 도구입니다. 상관계수로는 파악하기 어려운 데이터 포인트들의 분포와 특징을 살펴보면서, 변수 간의 선형적 관계뿐만 아니라 패턴이나 이상치를 발견할 수 있습니다.\n\n상관관계가 높은 변수 쌍 선택하기\n분석을 시작하기 전에, 상관계수가 특정 임계값 이상인 변수 쌍을 선택하여 살펴보겠습니다. 이는 분석의 초점을 명확히 하고, 더 의미 있는 관계를 탐색하기 위한 전략입니다:\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncorr_matrix = number_data.corr()\n\npairs = [(i, j, corr_matrix.at[i, j]) for i in corr_matrix.index for j in corr_matrix.columns if i != j]\npairs = sorted(pairs, key=lambda x: x[2], reverse=True)[::2]  # 같읂 값이 연속될 것으로 하나씩만 뽑습니다.\n\nfor pair in pairs[:10]:\n    print(f\"Columns: {pair[0]} & {pair[1]}, Correlation: {pair[2]:.2f}\")\n\nColumns: 월세(원) & 보증금(원), Correlation: 0.97\nColumns: 대표나이 & 나이, Correlation: 0.96\nColumns: 재계약횟수 & 거주개월, Correlation: 0.94\nColumns: 순번 & 아파트 평점, Correlation: 0.67\nColumns: 퇴거연도 & 거주연도, Correlation: 0.54\nColumns: 거주개월 & 퇴거연도, Correlation: 0.51\nColumns: 재계약횟수 & 퇴거연도, Correlation: 0.51\nColumns: 평형대 & 월세(원), Correlation: 0.39\nColumns: 입주연도 & 거주연도, Correlation: 0.34\nColumns: 평형대 & 보증금(원), Correlation: 0.31\n\n\n\n\n\n산포도로 상관관계 시각화하기\n상관관계가 높은 변수 쌍 중 하나인 보증금과 월세 간의 관계를 산포도로 그려봅니다. 이를 통해 두 변수 사이의 관계를 직관적으로 이해할 수 있습니다:\n\nsns.relplot(data=data, x=\"보증금(원)\", y=\"월세(원)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n분포와 함께 산포도 시각화하기\njointplot을 사용하여 보증금과 월세 간의 산포도와 함께 각 변수의 분포를 동시에 시각화합니다. 이는 변수 간의 관계뿐만 아니라 각 변수의 분포도 함께 확인할 수 있게 해줍니다:\n\nsns.jointplot(data=data, x=\"보증금(원)\", y=\"월세(원)\", kind=\"scatter\")\nplt.show()\n\n\n\n\n\n\n\n\n이 그래프는 보증금과 월세 간에 뚜렷한 상관관계가 있음을 보여줍니다. 또한, 대부분의 데이터 포인트가 낮은 보증금과 월세 값에 집중되어 있는 분포 특성을 보여줍니다.\n\n\n산포도로 복잡한 데이터 관계 탐색하기\n상관계수는 두 변수 간의 선형 관계의 강도를 나타내지만, 모든 관계가 선형적인 것은 아닙니다. 산포도를 통해 우리는 상관계수로는 확인하기 어려운 데이터 간의 복잡한 관계와 분포상의 특징을 살펴볼 수 있습니다.\n거주개월과 보증금 간의 관계\n\nsns.jointplot(data=data, x=\"거주개월\", y=\"보증금(원)\", kind=\"scatter\")\nplt.show()\n\n\n\n\n\n\n\n\n이 산포도에서는 거주개월과 보증금 간에 선형적이지 않은 관계가 나타납니다. 특히, 거주개월이 220개월을 넘어서면 보증금이 다시 하락하는 경향을 보이는 것으로, 단순히 선형 관계만으로는 설명할 수 없는 복잡한 패턴을 확인할 수 있습니다.\n\n\n상관계수가 높은 변수 쌍의 산포도 시각화\n상관계수가 높은 상위 10개 쌍과 낮은 하위 10개 쌍의 산포도를 그려, 다양한 변수 간의 관계를 더 깊이 탐색해 보겠습니다:\n\nextreme_20 = pairs[:10] + pairs[-10:]\nn = len(extreme_20)\nncols = 4  # 열의 수를 지정합니다.\nnrows = n//ncols + (0 if n%ncols == 0 else 1) #row 갯수를 정합니다. 딱 떨어지지 않으면 1줄을 더 추가합니다.\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(8, 8))  # 그래프 크기 조정\nfor i, (x, y, corr) in enumerate(extreme_20):\n    row, col = divmod(i, ncols)\n    sns.scatterplot(data=data, x=x, y=y, ax=axes[row][col])\n    axes[row][col].set_title(f\"상관계수: {corr:.2f}\", size=10)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n이러한 시각화를 통해, 상관계수가 높은 변수 쌍과 낮은 변수 쌍 간의 관계를 명확하게 이해할 수 있으며, 특정 변수 간에 예상치 못한 패턴이나 이상치가 있는지를 파악할 수 있습니다.\n\n\n\n결측치 확인하기\n결측치는 데이터 세트에서 종종 발생하는 문제입니다. 결측치는 다양한 이유로 발생할 수 있으며, 결측치가 발생하면 데이터 분석에 부정적인 영향을 미칠 수 있습니다. 따라서 결측치를 확인하고 적절하게 처리하는 것이 중요합니다.\n\n결측치 확인 방법\n결측치를 확인하는 방법에는 여러 가지가 있습니다. 가장 간단한 방법은 데이터 세트의 각 행과 열을 살펴보고 결측치가 있는지 확인하는 것입니다. 그러나 이 방법은 데이터 세트가 큰 경우에는 시간이 많이 걸릴 수 있습니다.\n결측치를 확인하는 보다 효율적인 방법은 결측치를 찾는 데 도움이 되는 통계 패키지를 사용하는 것입니다. 예를 들어, 파이썬의 pandas 패키지는 결측치를 확인하는 데 사용할 수 있는 isnull() 메서드를 제공합니다.\nisnull() 메서드는 결측치가 있는 행과 열을 True로 표시합니다. 따라서 이를 더하면 어떤 컬럼에 얼마나 결측치가 있는지 알 수 있습니다.\n\ndata.isnull().sum()\n\n순번             0\n계약구분         508\n재계약횟수          0\n거주개월           0\n아파트 이름         0\n아파트 ID         0\n아파트 평점      1225\n호실고유번호         0\n층              0\n평형대            0\n계약자고유번호        0\n계약서고유번호        0\n입주연도           0\n퇴거연도       61142\n거주연도           0\n월세(원)          0\n보증금(원)         0\n대표나이           0\n나이             0\n성별             0\n결혼여부           0\n거주자 수          0\n퇴거여부           0\ndtype: int64\n\n\n\n\n결측치 시각화하기\n결측치를 확인하는 또 다른 방법은 missingno 패키지를 이용하는 것입니다.\n\nimport missingno as msno\n\nmsno.matrix(data)\nplt.show()\n\n\n\n\n\n\n\n\n위의 그래프에서 볼 수 있듯이 데이터 세트의 대부분의 컬럼은 모두 값이 있으나 퇴거연도 값은 대부분 비어 있음을 알 수 있습니다.\n다음 글에서는 어떻게 대략적인 판단을 바탕으로 결측치와 이상치를 처리할지 알아보도록 하겠습니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html",
    "href": "data_science/posts/leos_syndrome.html",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "",
    "text": "이 글은 Leo’s Syndrome을 기반으로 작성하였습니다.\n재미있는 글을 발견하여 소개하고자 합니다.\n영화배우 레오나르도 디카프리오는 어린 여성과 사귀는 것으로 유명합니다. 어떤 분이 위에 글과 같이 깔끔하게 데이터 시각화를 하였는데요. 이는 Makie라고 하는 Julia 패키지를 사용하였습니다.\nMakie는 비교적 최근에 개발된 라이브러리 입니다. 여러 백엔드를 사용해서 개발할 수 있다는 특징을 가지고 있습니다만, 아직 초창기다보니 기본이 되는 백엔드는 GLMakie이며 이외에 여러가지 다양한 백엔드로 개발되고 있습니다.\n기본 문법 들을 하나 하나 살펴보도록 하겠습니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#패키지-불러오기",
    "href": "data_science/posts/leos_syndrome.html#패키지-불러오기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "패키지 불러오기",
    "text": "패키지 불러오기\n\nusing Downloads, GLMakie\nusing Colors, Statistics\nusing FileIO\n\n파이썬과 비슷하게 가장 먼저 볼 수 있는 건 패키지를 로딩하는 부분입니다. 파이썬과 같이 import를 사용할 수도 있지만, 줄리아에서는 using사용하는 것이 표준이 되는 방식입니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#백엔드-선택하기",
    "href": "data_science/posts/leos_syndrome.html#백엔드-선택하기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "백엔드 선택하기",
    "text": "백엔드 선택하기\n\nGLMakie.activate!()\n\n위에서 불러온 그래픽 패키지인 GLMakie를 활성화 시킵니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#파일명-합치기",
    "href": "data_science/posts/leos_syndrome.html#파일명-합치기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "파일명 합치기",
    "text": "파일명 합치기\n\nnames = [\"Leonardo Dicaprio\", \"Gisele Bundchen\", \"Bar Refaeli\",\n        \"Blake Lively\", \"Erin Heatherton\", \"Toni Garrn\", \"Kelly Rohrbach\",\n        \"Nina Agdal\", \"Camila Morrone\"]\nnamesfiles = join.(split.(lowercase.(names)), \"_\")\n\n이름을 정하고 파일명에 맞출 수 있도록 소문자로 변환하고 띄어쓰기를 “_“로 치환합니다. 줄리아는 Broadcasting을 .을 함수 뒤에 붙이는 것을 통해 별도의 조치 없이 적용이 가능합니다. 예를 들면 lowercase.(names)의 뜻은 name의 각 원소에 lowercase함수를 적용하라는 것과 같습니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#축에-들어갈-값을-생성하기",
    "href": "data_science/posts/leos_syndrome.html#축에-들어갈-값을-생성하기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "축에 들어갈 값을 생성하기",
    "text": "축에 들어갈 값을 생성하기\n\ny_xticks = 1998:2022\nys_xticks = string.(1998:2022)\nyd_xticks = [\"'\"*t[3:4] for t in ys_xticks]\nage_leo = 24 .+ collect(1:length(y_xticks)) .- 1\n\nage_gf = [18:23, 20:25, 23, 22, 20:21,25, 24:25, 20:25]\nyears = [1998:2003, 2004:2009, 2010, 2011, 2012:2013, 2014,\n    2015:2016, 2017:2022]\n\n각종 축에 사용될 값을 생성합니다. 줄리아에서는 :을 사용해서 연속된 정수 값을 표현할 수 있습니다. 예를 들면 1998:2022는 1998부터 2022까지 1씩 증가하는 것을 의미하며 파이썬에서 range(1998, 2023)과 동일 합니다. 줄리아는 파이썬과 다르게 범위를 포함하는 특징을 가지고 있습니다. 이는 수학에서 사용하는 것과 가능한 유사한 방식을 구현하기 위함으로 알고 있습니다.\n이름을 바꾸었던 것과 같이 string 함수를 적용해 ys_xticks를 생성했음을 알 수 있습니다. 이렇게 바꾼 이유는 뒤에 두글자만 가져와 yd_xticks를 만들기 위함 입니다.\n줄리아의 또다른 특징을 여기서 볼 수 있는데 문자열을 병합할 때 +기호가 아닌 *기호를 씁니다. 왜 이렇게 만들었는지 궁금한 부분이긴 한데 이미 많은 코드에 *가 사용되고 있고 바꾸는 실익이 거의 없다고 판단하여 유지되고 있다고 알고 있습니다.\n그다음에는 레오의 나이를 표기하고자 수열을 만들었습니다. 24 .+ collect(1:length(y_xticks)) .- 1을 통해 24살에서 1부터 길이까지의 수열을 만들고 1을 빼서 24살 부터 데이터 수 만큼 1씩 증가하는 수열을 만들었습니다. 여기서 collect라는 함수는 배열을 만드는 함수로 보시면 됩니다.\n또한 .+는 각각에 더하기 연산을 하라는 의미입니다.\n이 다음에는 레오나르도의 여자친구들의 나이와 기간이 적혀 있습니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#사진을-불러오는-함수",
    "href": "data_science/posts/leos_syndrome.html#사진을-불러오는-함수",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "사진을 불러오는 함수",
    "text": "사진을 불러오는 함수\n\nfunction getPicture(; name = \"leonardo_dicaprio\",\n        imgs_link = \"https://raw.githubusercontent.com/tashapiro/tanya-data-viz/main/dicaprio-gfs/images/\")\n    load(Downloads.download(joinpath(imgs_link, name * \".png\")))\nend\n\n줄리아에서 사진을 불러오는 함수를 만들었습니다. 줄리아는 파이썬과 다르게 function이란 키워드를 사용하여 함수를 만듭니다. 또한 기본값이 있는 파라미터를 지정할 경우에는 ; 뒤에 이름과 파라미터를 넣으면 됩니다. 이 또한 파이썬과 다른 특징이라고 볼 수 있습니다.\n이 함수는 링크 주소를 생성하고 그 데이터를 불러오는 함수입니다.\n줄리아에서 함수는 return을 지정하지 않을 경우 마지막 줄을 반환하는 특징이 있습니다. 이는 함수가 상태를 변화시키는 것이 아니라 수학에서 말하는 값을 반환하는 것을 기본으로 하고 있다고 생각하기 때문에 도입된 문법이라고 생각합니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#베지어-곡선을-만들어-주는-함수",
    "href": "data_science/posts/leos_syndrome.html#베지어-곡선을-만들어-주는-함수",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "베지어 곡선을 만들어 주는 함수",
    "text": "베지어 곡선을 만들어 주는 함수\n\nfunction poly3(t, p0, p1, p2, p3)\n    Point2f((1-t)^3 .* p0 .+ t*p1*(3*(1-t)^2) + p2*(3*(1-t)*t^2) .+ p3*t^3)\nend\n\n\nfunction BezierPath(o, f, co, cf; t = range(0,1, length=30))\n    return [poly3(t, o, co, cf, f) for t in t]\nend\n\n베지어 곡선을 만들기 위한 함수입니다. p0, p1, p2, p3 점을 지나는 베지어 곡선을 위해서 만들어진 함수 입니다.\n위의 poly3는 3차 함수이며 range()함수를 통해서 30개의 포인트를 부드럽게 생성하는 함수 입니다.\n\nfunction posFig(ax, x; yoff=100, ylow = 15)\n    o = ax.scene.px_area[].origin - Point2f(0, yoff)\n    return Makie.project(ax.scene, Point2f(x, ylow)) + o\nend\n\n피겨의 위치를 반환 합니다.\n\nfunction supLine(p1, p2; x=0,y=8)\n    [p1 .+ Point2f(x,y), p1, p2, p2 .+ Point2f(x,y)]\nend\n\n디긋을 어긋난 위치를 연결해서 보여줍니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#색과-사진",
    "href": "data_science/posts/leos_syndrome.html#색과-사진",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "색과 사진",
    "text": "색과 사진\n\npictures = [getPicture(; name = n) for n in namesfiles]\ncmap = resample_cmap(Reverse(:Hiroshige), 9)\nblue = colorant\"#6EE2FFFF\";\ngrey = colorant\"#D0DFE699\";\n\nαcolors = [blue, blue, (grey, 0.0), (grey,0.0)]\nαcolorsLeg = [blue, (grey, 0.0), (grey,0.0), blue]\n\n위에서 정의한 함수와 색감을 정합니다. 먼저 사진을 불러와 배열에 넣습니다. 그다음으로는 색깔 맵을 구합니다. resample_cmap이란 함수는 색 간격을 나누어 줍니다. Reverse함수를 통해서 색의 방향을 반대로 만든 후 9개의 단계로 샘플링을 하게 됩니다. 그후 두 색을 별도로 지정합니다. 그 지정 방식은 메크로를 활용하고 있습니다. 줄리아에서는 메크로라는 아주 강력하지만 위험한 기능이 있습니다. colorant\"#6EE2FFFF\";은 뒤 문자열을 색 타입으로 변환하는 매크로 입니다. 여러가지를 손쉽게 처리할 수 있어 아주 강력하지만, 잘못 사용하면 코드 가독성을 많이 떨어뜨리기에 조심해서 사용해야 합니다.\n그후 여러 색의 집합을 만들었습니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#범주를-위한-도형",
    "href": "data_science/posts/leos_syndrome.html#범주를-위한-도형",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "범주를 위한 도형",
    "text": "범주를 위한 도형\n\nlegleo = MarkerElement(color =1.2cmap[2:3:end], marker = :circle, markersize = 20,\n        points = Point2f[(0, 0.5), (1, 0.5), (2, 0.5)])\nleggirl = PolyElement(color = αcolorsLeg, strokecolor = :white, strokewidth = 0.85,\n    points = Point2f[(-0.2, 0), (2.2, 0), (2.2,1), (-0.2, 1)])\n\n레오나르도의 나이를 표현하기 위한 점 3개를 만들는 것과 여자친구의 나이를 나타내는 사각형을 만들었습니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#테마-블록",
    "href": "data_science/posts/leos_syndrome.html#테마-블록",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "테마 블록",
    "text": "테마 블록\n\nwith_theme(theme_black()) do\n...\nend\n\n테마 블록을 통해서 여러가지 기본이 되는 테마를 적용할 수 있습니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#그림-사이즈와-축-정하기",
    "href": "data_science/posts/leos_syndrome.html#그림-사이즈와-축-정하기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "그림 사이즈와 축 정하기",
    "text": "그림 사이즈와 축 정하기\n\n    fig = Figure(; resolution = (1200,800))\n    ax = Axis(fig[1,1:9], ylabel = \"Age [Years]\", xlabel = \"\")"
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#그래프-그리기",
    "href": "data_science/posts/leos_syndrome.html#그래프-그리기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "그래프 그리기",
    "text": "그래프 그리기\n\n    lines!(ax, y_xticks, age_leo; label = \"Leo's age\", color = age_leo,\n        linestyle = :dot, colormap = 1.2cmap[2:end])\n    scatter!(ax, y_xticks, age_leo; label = \"Leo's age\", color = age_leo,\n        markersize = 10, colormap = 1.2cmap[2:end])"
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#여자친구들의-나이-그래프-그리기",
    "href": "data_science/posts/leos_syndrome.html#여자친구들의-나이-그래프-그리기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "여자친구들의 나이 그래프 그리기",
    "text": "여자친구들의 나이 그래프 그리기\n\n    [barplot!.(years[i], age_gf[i]; color = αcolors,label = \"Girlfriend's age\",\n        strokewidth=0.85, strokecolor= (:white,1)) for i in eachindex(years)]\n\n    [scatter!(ax, [2009,2014, 2016, 2022], fill(25 +1,4);\n        color = (blue, 0.1), markersize = 50-3i) for i in 1:10]\n\n    lines!(ax,supLine(Point2f(2009,29), Point2f(2022,29); x=0,y=-3); color=blue)\n    lines!(ax,supLine(Point2f(2014,29), Point2f(2016,29); x=0,y=-3); color=blue)\n\n    text!(ax, \"Threshold\", position = (2014,30))\n    [text!(string.(age_gf[i]), position = Point2f.(years[i], age_gf[i] .+0.5),\n        align = (:center, :bottom), fontsize = 16) for i in eachindex(age_gf)]\n\n여자친구들의 나이를 기반으로 바 그래프를 하나씩 그리도록 합니다.\n또한 임계값에 대해서 강조하기 위한 동그라미를 그립니다.\n거기에 맞게 디귿 모양의 보조선을 그립니다.\n그리고 필요한 글자를 입력합니다.\n또한 연도도 표시하도록 입력합니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#레오나르도의-나이-입력하기",
    "href": "data_science/posts/leos_syndrome.html#레오나르도의-나이-입력하기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "레오나르도의 나이 입력하기",
    "text": "레오나르도의 나이 입력하기\n\n    text!(string.(age_leo), position = Point2f.(y_xticks, age_leo .+0.5),\n        align = (:center, :bottom), fontsize = 16)\n\n레오나르도의 나이 숫자를 표시합니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#축상-숫자-표시",
    "href": "data_science/posts/leos_syndrome.html#축상-숫자-표시",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "축상 숫자 표시",
    "text": "축상 숫자 표시\n\n    ax.xticks = (y_xticks, yd_xticks)\n    ax.yticks = 0:5:55\n    ylims!(ax,15,52)\n    xlims!(ax,1997,2023)\n    hidespines!.(ax)\n\n각 축의 단위를 표시하는 틱을 지정합니다.\n그후 임계값을 지정합니다.\n마지막으로 스파인을 숨깁니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#사진-배치",
    "href": "data_science/posts/leos_syndrome.html#사진-배치",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "사진 배치",
    "text": "사진 배치\n\n    # pictures\n    aximgs = [Axis(fig[2,i], aspect = 1, xlabel = join(split(names[i]), \"\\n\"),\n        xlabelcolor = blue) for i in 1:9]\n    [image!(aximgs[i], rotr90(pictures[i])) for i in eachindex(pictures)]\n    hidedecorations!.(aximgs; label =false)\n    hidespines!.(aximgs)\n    aximgs[1].xlabelcolor = \"#F79D1EFF\"\n    limits!.(aximgs,1,78,1,78)\n\n사진을 배치하기 전 이름을 줄바꿈으로 만들어 둡니다.\n그 다음 그림을 붙여 넣습니다. 90도를 회전 시키는 이유는 그림의 픽셀 배치가 90 차이가 나기 때문입니다.\n그 다음 그림 표시해주는 것을 생략하시고, 그림을 그립니다. 마지막으로 첫번째 그림의 색에 맞게 글자 색을 변경하고 그림 크기를 지정합니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#곡선으로-연결하기",
    "href": "data_science/posts/leos_syndrome.html#곡선으로-연결하기",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "곡선으로 연결하기",
    "text": "곡선으로 연결하기\n\n# connecting lines in fig space!\n    ops = [posFig(ax, mean(years[i]); yoff=250, ylow = 15) for i in 1:8]\n    fps = [posFig(aximgs[i], 39; yoff=120, ylow = 78) for i in 2:9]\n    supls = [supLine(posFig(ax, years[i][begin]; yoff=250, ylow = 15),\n        posFig(ax, years[i][end], yoff=250, ylow = 15)) for i in 1:8]\n    [lines!(fig.scene, supls[k], color = 1.2cmap[k+1]) for k in 1:8]\n    [lines!(fig.scene, BezierPath(ops[k], fps[k], [ops[k][1],ops[k][2]-30],\n        [fps[k][1],fps[k][2]+30]); color = 1.2cmap[k+1]) for k in 1:8]\n\n시작지점과 끝지점의 위치를 지정합니다. supls를 통해 위치를 지정하고 해당 점을 연결하여 디귿 모양의 부분을 먼저 생성합니다. 그 후 가운데 부분에 해당하는 위치에 맞도록 베지어 곡선을 통해 부드럽게 연결합니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#제목과-마무리",
    "href": "data_science/posts/leos_syndrome.html#제목과-마무리",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "제목과 마무리",
    "text": "제목과 마무리\n\n    rowsize!(fig.layout,2,Auto(0.2))\n    rowgap!(fig.layout, 60)\n    Legend(fig[1,1], [legleo, leggirl], [\"      Leo's age\", \"      Girlfriend's age\"],\n        halign = :left, valign = :top,tellheight=false,tellwidth=false,\n        margin = (30, 10, 10, 10), framecolor = (:white,0.2))\n    Label(fig[0,:], \"Leo's Syndrome\", color = \"#F79D1EFF\", textsize = 32)\n\n레이아웃을 조정하고 간격을 조정합니다. 이전에 생성해 둔 모양을 가지고 범례를 만듭니다.\n그 후 레이블을 활용해 제목을 만듭니다."
  },
  {
    "objectID": "data_science/posts/leos_syndrome.html#마무리",
    "href": "data_science/posts/leos_syndrome.html#마무리",
    "title": "Leo’s Syndrome with Julia Makie",
    "section": "마무리",
    "text": "마무리\n이 모든 과정을 다 모아서 아래와 같이 작성하면 위에서 보았던 이미지를 얻을 수 있습니다.\n이 모든 과정을 통해 우리는 Makie를 통해 어떻게 그림을 그릴 수 있는지 알 수 있었습니다.\n자동으로 위치를 잡아주고 연결해주는 등의 편의 기능은 부족하기에 실무에서 효과적일지에 대해서는 좀 더 알아보아야 할 것 같습니다.\n\nusing Downloads, GLMakie\nusing Colors, Statistics\nusing FileIO\n\nGLMakie.activate!()\n# some data\nnames = [\"Leonardo Dicaprio\", \"Gisele Bundchen\", \"Bar Refaeli\",\n        \"Blake Lively\", \"Erin Heatherton\", \"Toni Garrn\", \"Kelly Rohrbach\",\n        \"Nina Agdal\", \"Camila Morrone\"]\nnamesfiles = join.(split.(lowercase.(names)), \"_\")\n\ny_xticks = 1998:2022\nys_xticks = string.(1998:2022)\nyd_xticks = [\"'\"*t[3:4] for t in ys_xticks]\nage_leo = 24 .+ collect(1:length(y_xticks)) .- 1\n\nage_gf = [18:23, 20:25, 23, 22, 20:21,25, 24:25, 20:25]\nyears = [1998:2003, 2004:2009, 2010, 2011, 2012:2013, 2014,\n    2015:2016, 2017:2022]\n# helper functions\n# Inspired by https://github.com/tashapiro/tanya-data-viz/tree/main/dicaprio-gfs\nfunction getPicture(; name = \"leonardo_dicaprio\",\n        imgs_link = \"https://raw.githubusercontent.com/tashapiro/tanya-data-viz/main/dicaprio-gfs/images/\")\n    load(Downloads.download(joinpath(imgs_link, name * \".png\")))\nend\nfunction poly3(t, p0, p1, p2, p3)\n    Point2f((1-t)^3 .* p0 .+ t*p1*(3*(1-t)^2) + p2*(3*(1-t)*t^2) .+ p3*t^3)\nend\nfunction BezierPath(o, f, co, cf; t = range(0,1, length=30))\n    return [poly3(t, o, co, cf, f) for t in t]\nend\nfunction posFig(ax, x; yoff=100, ylow = 15)\n    o = ax.scene.px_area[].origin - Point2f(0, yoff)\n    return Makie.project(ax.scene, Point2f(x, ylow)) + o\nend\nfunction supLine(p1, p2; x=0,y=8)\n    [p1 .+ Point2f(x,y), p1, p2, p2 .+ Point2f(x,y)]\nend\n\npictures = [getPicture(; name = n) for n in namesfiles]\ncmap = resample_cmap(Reverse(:Hiroshige), 9)\nblue = colorant\"#6EE2FFFF\";\ngrey = colorant\"#D0DFE699\";\n# αcolors = [blue, grey, (grey, 0.1), (blue,0.65)] # try this one 😄\nαcolors = [blue, blue, (grey, 0.0), (grey,0.0)]\nαcolorsLeg = [blue, (grey, 0.0), (grey,0.0), blue]\n\nlegleo = MarkerElement(color =1.2cmap[2:3:end], marker = :circle, markersize = 20,\n        points = Point2f[(0, 0.5), (1, 0.5), (2, 0.5)])\nleggirl = PolyElement(color = αcolorsLeg, strokecolor = :white, strokewidth = 0.85,\n    points = Point2f[(-0.2, 0), (2.2, 0), (2.2,1), (-0.2, 1)])\n\nwith_theme(theme_black()) do\n    fig = Figure(; resolution = (1200,800))\n    ax = Axis(fig[1,1:9], ylabel = \"Age [Years]\", xlabel = \"\")\n    lines!(ax, y_xticks, age_leo; label = \"Leo's age\", color = age_leo,\n        linestyle = :dot, colormap = 1.2cmap[2:end])\n    scatter!(ax, y_xticks, age_leo; label = \"Leo's age\", color = age_leo,\n        markersize = 10, colormap = 1.2cmap[2:end])\n    [barplot!.(years[i], age_gf[i]; color = αcolors,label = \"Girlfriend's age\",\n        strokewidth=0.85, strokecolor= (:white,1)) for i in eachindex(years)]\n    [scatter!(ax, [2009,2014, 2016, 2022], fill(25 +1,4);\n        color = (blue, 0.1), markersize = 50-3i) for i in 1:10]\n    lines!(ax,supLine(Point2f(2009,29), Point2f(2022,29); x=0,y=-3); color=blue)\n    lines!(ax,supLine(Point2f(2014,29), Point2f(2016,29); x=0,y=-3); color=blue)\n    text!(ax, \"Threshold\", position = (2014,30))\n    [text!(string.(age_gf[i]), position = Point2f.(years[i], age_gf[i] .+0.5),\n        align = (:center, :bottom), fontsize = 16) for i in eachindex(age_gf)]\n    text!(string.(age_leo), position = Point2f.(y_xticks, age_leo .+0.5),\n        align = (:center, :bottom), fontsize = 16)\n    ax.xticks = (y_xticks, yd_xticks)\n    ax.yticks = 0:5:55\n    ylims!(ax,15,52)\n    xlims!(ax,1997,2023)\n    hidespines!.(ax)\n    # pictures\n    aximgs = [Axis(fig[2,i], aspect = 1, xlabel = join(split(names[i]), \"\\n\"),\n        xlabelcolor = blue) for i in 1:9]\n    [image!(aximgs[i], rotr90(pictures[i])) for i in eachindex(pictures)]\n    hidedecorations!.(aximgs; label =false)\n    hidespines!.(aximgs)\n    aximgs[1].xlabelcolor = \"#F79D1EFF\"\n    limits!.(aximgs,1,78,1,78)\n    # connecting lines in fig space!\n    ops = [posFig(ax, mean(years[i]); yoff=250, ylow = 15) for i in 1:8]\n    fps = [posFig(aximgs[i], 39; yoff=120, ylow = 78) for i in 2:9]\n    supls = [supLine(posFig(ax, years[i][begin]; yoff=250, ylow = 15),\n        posFig(ax, years[i][end], yoff=250, ylow = 15)) for i in 1:8]\n    [lines!(fig.scene, supls[k], color = 1.2cmap[k+1]) for k in 1:8]\n    [lines!(fig.scene, BezierPath(ops[k], fps[k], [ops[k][1],ops[k][2]-30],\n        [fps[k][1],fps[k][2]+30]); color = 1.2cmap[k+1]) for k in 1:8]\n    rowsize!(fig.layout,2,Auto(0.2))\n    rowgap!(fig.layout, 60)\n    Legend(fig[1,1], [legleo, leggirl], [\"      Leo's age\", \"      Girlfriend's age\"],\n        halign = :left, valign = :top,tellheight=false,tellwidth=false,\n        margin = (30, 10, 10, 10), framecolor = (:white,0.2))\n    Label(fig[0,:], \"Leo's Syndrome\", color = \"#F79D1EFF\", textsize = 32)\n    fig\n    save(\"leo.png\", fig)\nend"
  },
  {
    "objectID": "data_science/posts/regression_with_jax.html",
    "href": "data_science/posts/regression_with_jax.html",
    "title": "Jax를 사용해서 Regression을 그려 봅시다",
    "section": "",
    "text": "설치하기\nJAX를 설치해 봅시다. 설치를 할 때 먼저 jaxlib을 설치하고 그 버전에 맞는 jax를 설치합니다. 순서가 바뀐 경우 잘 안되는 문제가 발생하곤 했습니다.\nlinux에서는 문제가 없는 것으로 보이나 windows에서 실행할 경우에는 jaxlib whl에서 jaxlib을 받아서 설치해야 합니다.\n그리고 그 파일 버전에 맞춰서 jax를 설치해 주어야 합니다. 저 같은 경우에는 jax 0.3.7으로 설치했습니다.\npip install jaxlib-0.3.7-cp310-none-win_amd64.whl\npip install jax==0.3.7\n\n\n필요한 패키지를 불러옵니다\n\nfrom jax import numpy as jnp\nfrom jax import grad\nimport numpy as np\nfrom plotnine import *\nimport pandas as pd\nfrom tqdm import tqdm\n\n간단한 모형을 만들어 봅니다. X와 y가 2차함수 형태로 결합된 경우를 생각해 봅니다.\n\nn = 100\nX = np.random.uniform(0, 3, size=n)\ny = 3 * np.power(X, 2) + np.random.normal(10, 3, size=n)\n\ndata = pd.DataFrame(zip(X, y), columns=[\"X\", \"y\"])\n(\n    ggplot(data)\n    + aes(\"X\", \"y\")\n    + geom_point()\n)\n\n선형 모델을 먼저 생각해 봅니다.\n\nw = {\"a\": 0., \"b\": 0.}\n\n# set model\ndef model(w, X):\n    return w[\"a\"] * X + w[\"b\"]\n\n# set loss\ndef loss(w, model, X, y):\n    return jnp.power(model(w, X) - y, 2).sum()\n\n# grad loss\ndloss = grad(loss)\n\n이제 경사하강법을 활용하여 w를 찾아봅니다.\n경사하강법은 말그대로 경사를 구해서 낮은 쪽으로 이동하게 하는 것입니다.\n기본적인 아이디어는 예측치와 관측값의 차이를 합치는 손실함수(loss function)을 구합니다. 그리고 파라미터를 손실이 줄어드는 방향(경사, 미분해서 보통 구합니다)으로 조금씩 옮겨가면서 최적의 값을 찾아 한발 한발 나아가는 방식입니다.\n수식으로 간단하게 표기해보자면 \\[Loss = \\sum_i f(w, data_i)\\] 로 정의하고 \\(\\sum_i f(w, data_i)\\)를 \\(w\\)로 미분해서 해당 미분값(경사)를 이용해서 낮추는 방향으로 파라미터를 바꿔가면서 찾아가는 방식입니다.\n\nrate = 0.0001\n\nlosses = []\nws = []\nfor i in tqdm(range(100)):\n    l = loss(w, model, X, y)\n    ws.append(w.copy())\n    losses.append(l)\n    dw = dloss(w, model, X, y)\n    for key in w.keys():\n        w[key] -= dw[key]*rate \n\n\n# overlay plots\nresult_df = pd.DataFrame(zip(X, np.array(model(w, X))), columns=[\"X\", \"f\"])\n(\n    ggplot(data=data) +\n    aes(\"X\", \"y\") +\n    geom_point() +\n    geom_smooth(method=\"lm\") +\n    geom_line(data=result_df, mapping=aes(\"X\", \"f\"),  color=\"#ff1234\")\n    \n)\n\n\ndfs = [pd.DataFrame(zip(map(int, np.ones_like(X)*i), X, np.array(model(ws[i], X))), columns=[\"i\", \"X\", \"f\"]) for i in range(0, 50, 5)]\ndf = pd.concat(dfs)\n\n처음에는 많이 차이나지만 점점 해석적으로 계산한 선형 회귀 값과 유사해지는 것을 볼 수 있습니다.\n이 경사하강법의 장점은 손실함수를 정의 할 수만 있다면 적용할 수 있어 유연하게 많은 곳에 적용할 수 있습니다.\n\np = (\n    ggplot(data=df) +\n    aes(x=\"X\", y=\"f\") +\n    geom_point(data=data, mapping=aes(\"X\", \"y\")) +\n    geom_smooth(data=data, method=\"lm\", mapping=aes(\"X\", \"y\"), color=\"yellow\") +\n    geom_line(color=\"red\", size=1) +\n    facet_wrap(\"i\")\n)\np\n\n하나의 그래프에 겹쳐서 표현하면 아래와 같은 그래프가 됩니다.\n\np = (ggplot() +\n    geom_point(data=data, mapping=aes(\"X\", \"y\")) +\n    geom_smooth(data=data, method=\"lm\", mapping=aes(\"X\", \"y\"), color=\"yellow\")\n)\n\nfor df in dfs:\n    p += geom_line(data=df, mapping=aes(x=\"X\", y=\"f\", color=\"i\"))\n\n\np"
  },
  {
    "objectID": "data_science/posts/sir_model.html",
    "href": "data_science/posts/sir_model.html",
    "title": "SIR모델을 사용해 코로나 발병 예측하기 with Julia",
    "section": "",
    "text": "코로나19로 인해 감염병 모델링에 대한 관심이 높아졌습니다. 질병이 어떻게 퍼져나가는지 예측할 수 있는 건 이후 대응을 위해서도 아주 중요한 지식임을 많은 사람들이 알게 되었습니다. 여러가지 예측하는 방법이 있습니다만, 오늘은 수리 모델링을 통해서 이에 대해서 알아보고자 합니다.\n수리 모델(Methmetical Model)은 계산모델(Computational Model)이라고도 할 수 있습니다. 현상에 대해서 우리가 아는 내용을 수식으로 정리하고 이후 어떻게 변해가는지를 계산하는 방식이라고 할 수 있습니다. 감염병 확산에 대한 수리 모델은 여러가지 갈래로 발전하고 있는데 일반적으로 가장 간단한 모델로 SIR 모델를 뽑습니다."
  },
  {
    "objectID": "data_science/posts/sir_model.html#sir-모델",
    "href": "data_science/posts/sir_model.html#sir-모델",
    "title": "SIR모델을 사용해 코로나 발병 예측하기 with Julia",
    "section": "SIR 모델",
    "text": "SIR 모델\n감염병에 대한 수치적 모델의 대표적인 모델이 SIR 모델입니다. SIR은 Susceptible, Infected, Recovered의 첫 글자를 모은 것입니다. 저 3가지 상태로 사람들이 분류 된다고 보고 이에 대한 모델을 만드는 것입니다.\n이에 대해서는 당연하다고 생각되는 몇가지 가정을 수식으로 만들었습니다.\n\n새롭게 감염된 사람들의 수 만큼 미감염자(Susceptible)의 수는 줄어들 것이다.\n새롭게 감염된 사람들의 수 만큼 감염자(Infected)는 늘어날 것이다.\n새롭게 회복된 사람들의 수 만큼 감염자 수는 줄어 들 것이다.\n새롭게 회복된 인원의 수 만큼 회복된 인원(Recovered)은 늘어날 것이다.\n\n이 모델은 아래와 같이 일방향으로 사람들의 상태가 변해가는 것을 볼 수 있습니다. 따라서 장기적으로 보면 모두 회복된 사람들이 될 것입니다.\n\n\n\n\n\n\n\n\n\n\n\n새롭게 감염되는 사람과 새롭게 회복되는 사람에 대해서 몇가지 가정이 추가 됩니다.\n\n새롭게 감염되는 사람의 수는 이전 미감염된 사람의 수가 많을 수록 많아지며 그 수는 감염자 비율이 높을 수록 커질 것이다.\n새롭게 회복되는 사람의 수는 감염자 수가 많을 수록 많을 것이다.\n\n이 가정들을 모아서 아래와 같이 수식으로 만들 수 있습니다.\n\\[\n\\frac{dS}{dt} = - \\beta \\frac{S \\cdot I}{N}\n\\] \\[\n\\frac{dI}{dt} = \\beta \\frac{S \\cdot I}{N} - \\gamma I\n\\] \\[\n\\frac{dR}{dt} = \\gamma I\n\\]\n이제 이 아이디어를 코딩으로 옮겨 보고자 합니다."
  },
  {
    "objectID": "data_science/posts/sir_model.html#sir모델-코딩하기",
    "href": "data_science/posts/sir_model.html#sir모델-코딩하기",
    "title": "SIR모델을 사용해 코로나 발병 예측하기 with Julia",
    "section": "SIR모델 코딩하기",
    "text": "SIR모델 코딩하기\n\n\n\n\n\n\n왜 줄리아인가?\n\n\n\n줄리아는 2012년 공개된 새로운 프로그래밍 언어 입니다. 과학적 계산을 목표로 만들어진 언어로 아직 사용자는 적지만 주목을 받고 있는 언어입니다.\n인터프리터 언어인 파이썬의 느린 속도를 해결하면서도 파이썬 만큼 사용하기 쉬운 언어라고 소개되곤 합니다. 파이썬 만큼 쓰기 편한 것은 모르겠지만, 과학을 하기에는 정말 좋은 언어라고 생각합니다.\n\n\n\n필요한 패키지 설치하기\n줄리아는 Pkg 모듈을 사용해서 아래와 같이 필요한 패키지를 설치할 수 있습니다.\n줄리아 패키지 설치가 상당히 많은 시간이 소요될 수 있습니다.\n\n\nCode\nusing Pkg\n\nPkg.add([\"Turing\", \"LazyArrays\", \"Random\", \"DifferentialEquations\", \"Plots\", \"StatsPlots\", \"LaTeXStrings\", \"Downloads\", \"DataFrames\", \"CSV\", \"Chain\", \"Dates\"])"
  },
  {
    "objectID": "data_science/posts/sir_model.html#sir-모델-만들기",
    "href": "data_science/posts/sir_model.html#sir-모델-만들기",
    "title": "SIR모델을 사용해 코로나 발병 예측하기 with Julia",
    "section": "SIR 모델 만들기",
    "text": "SIR 모델 만들기\n줄리아는 위의 수식을 아래와 같이 정리할 수 있습니다. du, u, p, t를 지정해야 합니다.\n여기서 p는 파라미터, t는 시간을 의미하며 u는 변수이며 du는 그 1차 미분을 의미합니다. 이것을 바탕으로 위의 수식을 최대한 비슷하게 작성할 수 있습니다.\n\n\nCode\nusing DifferentialEquations\n\nfunction sir_ode!(du, u, p, t)\n    (S, I, R) = u\n    (β, γ) = p\n    N = S + I + R    # N은 전체 인원입니다.\n    infection = β * I * S / N \n    recovery = γ * I\n    @inbounds begin\n        du[1] = -infection # u의 첫번째 아이템의 전미분인 미감염자의 비율입니다.\n        du[2] = infection - recovery # Infected\n        du[3] = recovery # Recovered\n    end\n    nothing\nend;\n\n\n붉은색 선을 보시면 감여자 수가 피크를 그리고나면 점차 줄어드는 것을 볼 수 있습니다.\n\n\nCode\nusing Plots, StatsPlots, LaTeXStrings\n\nsusceptible = 10_000_000.0\ninfected = 10.0\nrecovered = 0.0 \n\nu = [susceptible, infected, recovered]\np = [0.5, 0.03]\nprob = ODEProblem(sir_ode!, u, (1.0, 100.0), p)\nsol_ode = solve(prob)\nplot(sol_ode, label=[L\"S\" L\"I\" L\"R\"],\n    lw=3,\n    xlabel=L\"t\",\n    ylabel=L\"N\",\n    yformatter=y -&gt; string(round(Int64, y ÷ 1_000_000)) * \"mi\",\n    title=\"SIR Model for 100 days, β = $(p[1]), γ = $(p[2])\")\n\n\n이 그래프를 여러가지 파라미터를 바꿔가면서 그려 보면 \\(\\beta\\)는 얼마나 빠르게 올라가는지 그리고 피크가 어디에 위치하는지를 결정한다면, \\(\\gamma\\)는 피크의 높이를 결정한다는 걸 볼 수 있습니다.\n\n\nCode\nbeta = 0.1:0.3:1.0\ngamma = 0.01:0.03:0.1\n\nfunction plots(beta, gamma, susceptible, infected, recovered) \n    u = [susceptible, infected, recovered]\n    charts = []\n    for (b, g) in [(b,g) for b in beta for g in gamma]\n        p = [b, g]\n        prob = ODEProblem(sir_ode!, u, (1.0, 100.0), p)\n        sol_ode = solve(prob)\n        chart = plot(sol_ode, \n            lw=3,\n            xlabel=L\"t\",\n            yformatter=y -&gt; string(round(Int64, y ÷ 1_000_000)) * \"mi\",\n            title=\"β = $(p[1]), γ = $(p[2])\", legend=false)\n        push!(charts, chart)\n    end\n    return charts\nend\n\ncharts = plots(beta,gamma, susceptible, infected, recovered)\nmap((chart) -&gt; plot!(chart, ylabel=L\"N\"), charts[1:4:16])\n\nplot(charts..., layout=(4, 4), \nsize=(850, 800), plot_title=\"SIR Model for 100 days\", label=[L\"S\" L\"I\" L\"R\"],)"
  },
  {
    "objectID": "data_science/posts/sir_model.html#마치며",
    "href": "data_science/posts/sir_model.html#마치며",
    "title": "SIR모델을 사용해 코로나 발병 예측하기 with Julia",
    "section": "마치며",
    "text": "마치며\n간단한 가정을 가지고 모델을 만드는 것을 연습해보았습니다. 단순한 몇가지 가정만으로도 우리는 피크에 다다르는 모델을 볼 수 있었습니다. 그럼 이제 실제 데이터를 가지고 저 파라미터가 재생산지수와 어떤 관게가 있는지, 파라미터를 어떻게 알 수 있을지 다음 포스트로 알아보도록 하겠습니다."
  },
  {
    "objectID": "data_science/posts/turing_tutorial_01.html",
    "href": "data_science/posts/turing_tutorial_01.html",
    "title": "줄리아와 Turing.jl을 이용한 베이지안 통계 (1): 개관",
    "section": "",
    "text": "Bayesian Statsitics using Julia and Turing이라는 온라인 책이 있습니다.\nCreative Commons Attribution-ShareAlike 4.0 Internacional라이센스를 고려하여 이 구조를 따라서 재구성을 해보고자 합니다.\n개인적인 관심이 있어 시작하는 프로젝트로 총 13개의 파트로 구성될 예정입니다.\n완전히 동일하게 진행하기 보다는 조금 설명을 덧붙이며 진행하도록 하겠습니다."
  },
  {
    "objectID": "data_science/posts/turing_tutorial_01.html#프로젝트-소개",
    "href": "data_science/posts/turing_tutorial_01.html#프로젝트-소개",
    "title": "줄리아와 Turing.jl을 이용한 베이지안 통계 (1): 개관",
    "section": "",
    "text": "Bayesian Statsitics using Julia and Turing이라는 온라인 책이 있습니다.\nCreative Commons Attribution-ShareAlike 4.0 Internacional라이센스를 고려하여 이 구조를 따라서 재구성을 해보고자 합니다.\n개인적인 관심이 있어 시작하는 프로젝트로 총 13개의 파트로 구성될 예정입니다.\n완전히 동일하게 진행하기 보다는 조금 설명을 덧붙이며 진행하도록 하겠습니다."
  },
  {
    "objectID": "data_science/posts/turing_tutorial_01.html#베이지안-통계란",
    "href": "data_science/posts/turing_tutorial_01.html#베이지안-통계란",
    "title": "줄리아와 Turing.jl을 이용한 베이지안 통계 (1): 개관",
    "section": "베이지안 통계란?",
    "text": "베이지안 통계란?\n베이지안 통계는 베이즈 정리를 기반으로 하는 추론적 통계 방법입니다. 통계 모델의 매개변수 분포를 관측 데이터의 정보를 사용하여 업데이트를 하여 추론합니다. 모델에 대한 지식은 사전 분포로 표현되며, 관측 데이터는 우도 함수 형태로 사전 분포와 결합하여 사후 분포를 결정합니다. 사후 분포는 미래 이벤트에 대한 예측에도 사용될 수 있습니다.\n베이지안 통계가 전통적인 빈도주의 통계와의 근본적인 차이는 확률변수에 대한 관점 입니다. 전통적인 통계는 파라미터 값이 고정되어 있고 우리가 관측하게 될 값이 확률에 따라 나타는 불확실한 부분(확률변수)로 바라봅니다. 하지만 베이지안 통계는 우리가 관측한 값은 고정되어 있고 파라미터 값이 불확실한 확률변수로 바라봅니다. 이 근본적인 관점의 차이에도 불구하고 대부분의 경우 거의 동일한 결과를 나타냅니다.\n그러면 왜 굳이 베이지안 통계를 사용하게 될까요? 베이지안 통계가 최근에 각광 받게 된 이유 중 하나는 점진적으로 업데이트를 진행할 수 있기 때문입니다. 빈도주의 통계에서는 새로운 데이터가 생겼을 때 새롭게 모델을 구축하고 산출해야 하지만, 베이지안 통계에서는 기존 데이터를 반영한 모델을 사전 분포로 사용하고 관측 데이터를 결합할 수 있어 점진적인 모델링이 가능한 장점이 있습니다."
  },
  {
    "objectID": "data_science/posts/turing_tutorial_01.html#julia-언어란",
    "href": "data_science/posts/turing_tutorial_01.html#julia-언어란",
    "title": "줄리아와 Turing.jl을 이용한 베이지안 통계 (1): 개관",
    "section": "Julia 언어란?",
    "text": "Julia 언어란?\n\n\n\n\n\nJulia는 LLVM을 사용하여 Just-in-time(JIT)으로 네이티브 코드로 컴파일하는 빠른 동적 유형 언어입니다. “C처럼 실행되지만 Python처럼 읽는다”는 의미로, 매우 빠르고 프로토타입을 만들고 코드를 읽고 쓰기 쉽습니다. 많은 현대적 언어와 유사하게 명령형, 함수형, 객체 지향 프로그래밍의 기능을 결합한 다중 패러다임 언어입니다. Julia의 기본 사항과 Julia를 사용한 모든 종류의 데이터 조작에 대해서는 이 튜토리얼에서는 다루지 않을 것입니다. 대신 Julia에 대한 소개와 Julia에서 테이블 형식의 데이터를 다루는 방법에 대한 다음 리소스를 찾아보세요.\n\nJulia Documentation: Julia documentation은 언어의 기본 디자인과 기능을 설명하는 매우 친절하고 잘 쓰여진 자료입니다. Julia Korea에서 번역한 한국어 자료도 있습니다.\nJulia Data Science: Julia를 사용하여 어떻게 데이터 과학을 할 수 있는지 소개해주는 책입니다.\nThinking Julia: Julia 언어 뒤에 있는 주요 개념과 기능을 설명하는 입문자 친화적인 책입니다.\nJulia High Performance : Julia Language의 두 창시자(Avik Sengupta와 Alan Edelman)가 쓴 책으로, 일부 원칙과 트릭으로 Julia를 더 빠르게 만드는 방법을 다룹니다.\nAn Introduction DataFrames: 패키지 DataFrames.jl은 Julia에서 테이블 형식의 데이터를 다루는 데 사용할 수 있는 도구를 제공합니다. 이 패키지의 디자인과 기능은 pandas(Python)와 data.frame, data.table 및 dplyr(R)과 유사하며 특히 R 또는 Python에서 Julia로 넘어오는 사람들에게 유용한 데이터 과학 도구입니다. 링크는 DataFrames.jl의 주요 기여자 중 한 명인 Bogumił Kamiński가 만든 DataFrames.jl을 소개하는 노트북 모음입니다."
  },
  {
    "objectID": "data_science/posts/turing_tutorial_01.html#turing.jl-이란",
    "href": "data_science/posts/turing_tutorial_01.html#turing.jl-이란",
    "title": "줄리아와 Turing.jl을 이용한 베이지안 통계 (1): 개관",
    "section": "Turing.jl 이란?",
    "text": "Turing.jl 이란?\nTuring은 확률적 프로그래밍을 사용하여 베이지안 추론을 할 수 있게 도와주는 Julia 패키지 입니다. Turing을 사용하면 읽기 쉬운 베이지안 확률 모델을 만들 수 있습니다. 모델은 수식으로 적는 방식과 동일하게 동작합니다. Julia의 모든 것과 마찬가지로 Turing은 빠른 특징을 가지고 있습니다."
  }
]